{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db7294bc",
   "metadata": {},
   "source": [
    "# Scrape and add most recent seasons to all time results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e30bd9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "### Parse the current season schedule / results page\n",
    "\n",
    "def parse_current_season(url):\n",
    "        # Initialize variables\n",
    "    current_date = None\n",
    "    current_conference = None\n",
    "    game_notes = None\n",
    "\n",
    "    # Initialize an empty list to hold the data\n",
    "    data = []\n",
    "\n",
    "    # Parse the page with BeautifulSoup\n",
    "    # Get the page with requests\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # select the table or tables\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    rows = soup.find_all('tr')\n",
    "\n",
    "    # Loop through each row to find relevant information\n",
    "    for row in rows:\n",
    "        # Check for date row\n",
    "        if row.get('class') == ['stats-section']:\n",
    "            current_date = row.find('td').text.strip()\n",
    "        # Check for conference row\n",
    "        elif row.get('class') == ['sked-header']:\n",
    "            current_conference = row.find('td').text.strip()\n",
    "        # Check for game notes\n",
    "        elif len(row.find_all('td')) == 2:\n",
    "            game_notes = row.find_all('td')[1].text.strip()\n",
    "        # Process rows with game data\n",
    "        elif row.get('valign') == 'top':\n",
    "            cells = row.find_all('td')\n",
    "            if len(cells) >= 9:\n",
    "                home_team = cells[0].text.strip()\n",
    "                # Remove any hyphens from the team name\n",
    "                home_team = home_team.replace('-', ' ')\n",
    "                home_team_link = cells[0].find('a')['href'] if cells[0].find('a') else None\n",
    "                home_score = cells[1].text.strip()\n",
    "                away_team = cells[3].text.strip()\n",
    "                away_team_link = cells[3].find('a')['href'] if cells[3].find('a') else None\n",
    "                away_score = cells[4].text.strip()\n",
    "                ot = cells[5].text.strip()\n",
    "                box_link = cells[7].find('a')['href'] if cells[7].find('a') else None\n",
    "                metrics_link = cells[8].find('a')['href'] if cells[8].find('a') else None\n",
    "                # Capture Game Notes\n",
    "                game_notes_cell = cells[-1].find('small')\n",
    "                game_notes = game_notes_cell.text.strip() if game_notes_cell else None\n",
    "\n",
    "                # Append data to the list\n",
    "                data.append([current_date, current_conference, game_notes, home_team, home_team_link, home_score, away_team, away_team_link, away_score, ot, box_link, metrics_link])\n",
    "                game_notes = None  # Reset game notes for the next row\n",
    "    return data\n",
    "\n",
    "\n",
    "### Set The Target Year\n",
    "# current_year_url = \"https://www.collegehockeynews.com/schedules/?season=20242025\" # 2024-2025 season\n",
    "current_year_url = \"https://www.collegehockeynews.com/schedules/?season=20232024\" # 2023-2024 season\n",
    "## call the function\n",
    "data = parse_current_season(current_year_url)\n",
    "\n",
    "\n",
    "# Create a dataframe from the list\n",
    "\n",
    "columns = ['Date', 'Conference', 'Game_Notes', 'Home_Team', 'Home_Team_Link', 'Home_Score', 'Away_Team', 'Away_Team_Link', 'Away_Score', 'OT', 'Box_Link', 'Metrics_Link']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "            \n",
    "## Extract the day of the week from the date and save in new column\n",
    "df['Day'] = pd.to_datetime(df['Date']).dt.day_name()\n",
    "# remove day of the week from date\n",
    "# format data column as YYYY-MM-DD\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "### Create a new column for the game ID\n",
    "## Game ID will be a combination of the date and abbreviated team names\n",
    "\n",
    "# Loop to abbreviate the team names\n",
    "for row in df.itertuples():\n",
    "    home_team = row.Home_Team\n",
    "    away_team = row.Away_Team\n",
    "    home_team_abbr = home_team.split(' ')[-1]\n",
    "    away_team_abbr = away_team.split(' ')[-1]\n",
    "    # Remove any hyphens from the team name if there are any\n",
    "    home_team_abbr = home_team_abbr.replace('-', ' ')\n",
    "    away_team_abbr = away_team_abbr.replace('-', ' ')\n",
    "    game_id = f'{row.Date}-{home_team_abbr}-{away_team_abbr}'\n",
    "    df.loc[row.Index, 'Game_ID'] = game_id\n",
    "\n",
    "# Create a new column for the game ID\n",
    "df['Game_ID'] = df['Game_ID'].str.replace(',', '')\n",
    "\n",
    "# Remove any hyphens from the team names if any\n",
    "df['Home_Team'] = df['Home_Team'].str.replace('-', ' ')\n",
    "df['Away_Team'] = df['Away_Team'].str.replace('-', ' ')\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df['Game_ID'] = df.apply(lambda row: f'{row.Date}-{row.Home_Team}-{row.Away_Team}', axis=1)\n",
    "\n",
    "## Filter out games that have not been played yet\n",
    "df = df[df['Home_Score'] != '']\n",
    "\n",
    "# Replace Nan values in metrics column with empty string\n",
    "df['Metrics_Link'] = df['Metrics_Link'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f58d154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Conference",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Game_Notes",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Home_Team",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Home_Team_Link",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Home_Score",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Away_Team",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Away_Team_Link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Away_Score",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "OT",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Box_Link",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Metrics_Link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Day",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Game_ID",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "c5194917-1cf3-4cb9-9fcf-05ddf7ff2c66",
       "rows": [
        [
         "0",
         "2023-10-06",
         "Exhibition",
         "",
         "Arizona",
         null,
         "0",
         "Arizona State",
         "/reports/team/Arizona-State/61",
         "16",
         "",
         null,
         "",
         "Friday",
         "2023-10-06-Arizona-Arizona State"
        ],
        [
         "1",
         "2023-10-07",
         "Exhibition",
         "",
         "McGill",
         null,
         "0",
         "Vermont",
         "/reports/team/Vermont/55",
         "4",
         "",
         null,
         "",
         "Saturday",
         "2023-10-07-McGill-Vermont"
        ],
        [
         "2",
         "2023-10-07",
         "Exhibition",
         "",
         "Merrimack",
         "/reports/team/Merrimack/29",
         "3",
         "Sacred Heart",
         "/reports/team/Sacred-Heart/51",
         "2",
         "ot",
         null,
         "",
         "Saturday",
         "2023-10-07-Merrimack-Sacred Heart"
        ],
        [
         "3",
         "2023-10-07",
         "Exhibition",
         "",
         "Union",
         "/reports/team/Union/54",
         "2",
         "Rensselaer",
         "/reports/team/Rensselaer/48",
         "2",
         "ot",
         null,
         "",
         "Saturday",
         "2023-10-07-Union-Rensselaer"
        ],
        [
         "4",
         "2023-10-07",
         "Exhibition",
         "",
         "Royal Military",
         null,
         "3",
         "Niagara",
         "/reports/team/Niagara/39",
         "8",
         "",
         null,
         "",
         "Saturday",
         "2023-10-07-Royal Military-Niagara"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Conference</th>\n",
       "      <th>Game_Notes</th>\n",
       "      <th>Home_Team</th>\n",
       "      <th>Home_Team_Link</th>\n",
       "      <th>Home_Score</th>\n",
       "      <th>Away_Team</th>\n",
       "      <th>Away_Team_Link</th>\n",
       "      <th>Away_Score</th>\n",
       "      <th>OT</th>\n",
       "      <th>Box_Link</th>\n",
       "      <th>Metrics_Link</th>\n",
       "      <th>Day</th>\n",
       "      <th>Game_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-06</td>\n",
       "      <td>Exhibition</td>\n",
       "      <td></td>\n",
       "      <td>Arizona</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>Arizona State</td>\n",
       "      <td>/reports/team/Arizona-State/61</td>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>Friday</td>\n",
       "      <td>2023-10-06-Arizona-Arizona State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>Exhibition</td>\n",
       "      <td></td>\n",
       "      <td>McGill</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>/reports/team/Vermont/55</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-10-07-McGill-Vermont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>Exhibition</td>\n",
       "      <td></td>\n",
       "      <td>Merrimack</td>\n",
       "      <td>/reports/team/Merrimack/29</td>\n",
       "      <td>3</td>\n",
       "      <td>Sacred Heart</td>\n",
       "      <td>/reports/team/Sacred-Heart/51</td>\n",
       "      <td>2</td>\n",
       "      <td>ot</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-10-07-Merrimack-Sacred Heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>Exhibition</td>\n",
       "      <td></td>\n",
       "      <td>Union</td>\n",
       "      <td>/reports/team/Union/54</td>\n",
       "      <td>2</td>\n",
       "      <td>Rensselaer</td>\n",
       "      <td>/reports/team/Rensselaer/48</td>\n",
       "      <td>2</td>\n",
       "      <td>ot</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-10-07-Union-Rensselaer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>Exhibition</td>\n",
       "      <td></td>\n",
       "      <td>Royal Military</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>Niagara</td>\n",
       "      <td>/reports/team/Niagara/39</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-10-07-Royal Military-Niagara</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Conference Game_Notes       Home_Team  \\\n",
       "0  2023-10-06  Exhibition                    Arizona   \n",
       "1  2023-10-07  Exhibition                     McGill   \n",
       "2  2023-10-07  Exhibition                  Merrimack   \n",
       "3  2023-10-07  Exhibition                      Union   \n",
       "4  2023-10-07  Exhibition             Royal Military   \n",
       "\n",
       "               Home_Team_Link Home_Score      Away_Team  \\\n",
       "0                        None          0  Arizona State   \n",
       "1                        None          0        Vermont   \n",
       "2  /reports/team/Merrimack/29          3   Sacred Heart   \n",
       "3      /reports/team/Union/54          2     Rensselaer   \n",
       "4                        None          3        Niagara   \n",
       "\n",
       "                   Away_Team_Link Away_Score  OT Box_Link Metrics_Link  \\\n",
       "0  /reports/team/Arizona-State/61         16         None                \n",
       "1        /reports/team/Vermont/55          4         None                \n",
       "2   /reports/team/Sacred-Heart/51          2  ot     None                \n",
       "3     /reports/team/Rensselaer/48          2  ot     None                \n",
       "4        /reports/team/Niagara/39          8         None                \n",
       "\n",
       "        Day                            Game_ID  \n",
       "0    Friday   2023-10-06-Arizona-Arizona State  \n",
       "1  Saturday          2023-10-07-McGill-Vermont  \n",
       "2  Saturday  2023-10-07-Merrimack-Sacred Heart  \n",
       "3  Saturday        2023-10-07-Union-Rensselaer  \n",
       "4  Saturday  2023-10-07-Royal Military-Niagara  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### INSPECT RESULTING DATAFRAME\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0eed53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename to df_2024\n",
    "# df_2024 = df.copy()\n",
    "df_2023 = df.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db1706f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the resulting DataFrames 2023 and 2024 and combine\n",
    "# df_2023.head(), df_2024.head()\n",
    "\n",
    "df_new = pd.concat([df_2023, df_2024], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2c5918b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Conference",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Home_Team",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Home_Team_Link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Home_Score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Away_Team",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Away_Team_Link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Away_Score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OT",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Game_Notes",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Game_ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Day",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Season_Year",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "59d0e02c-a9a1-47ae-9c1b-e69555e6ed3b",
       "rows": [
        [
         "53647",
         "3/26/2023",
         "NCAA Tournament, Bridgeport Regional (at Total Mortgage Arena, Bridgeport, Conn.)",
         "Ohio State",
         "/reports/team/Ohio-State/44",
         "1",
         "Quinnipiac",
         "/reports/team/Quinnipiac/47",
         "4",
         null,
         "Bridgeport Regional Final",
         "2023-03-26_Ohio State_Quinnipiac",
         "Sunday",
         "2022"
        ],
        [
         "53648",
         "3/26/2023",
         "NCAA Tournament, Allentown Regional (at PPL Center, Allentown, Pa.)",
         "Penn State",
         "/reports/team/Penn-State/60",
         "1",
         "Michigan",
         "/reports/team/Michigan/31",
         "2",
         "ot",
         "Allentown Regional Final",
         "2023-03-26_Penn State_Michigan",
         "Sunday",
         "2022"
        ],
        [
         "53649",
         "4/6/2023",
         "NCAA Tournament (at Amalie Arena, Tampa, Fla.)",
         "Boston University",
         "/reports/team/Boston-University/10",
         "2",
         "Minnesota",
         "/reports/team/Minnesota/34",
         "6",
         null,
         "National Semifinal",
         "2023-04-06_Boston University_Minnesota",
         "Thursday",
         "2022"
        ],
        [
         "53650",
         "4/6/2023",
         "NCAA Tournament (at Amalie Arena, Tampa, Fla.)",
         "Michigan",
         "/reports/team/Michigan/31",
         "2",
         "Quinnipiac",
         "/reports/team/Quinnipiac/47",
         "5",
         null,
         "National Semifinal",
         "2023-04-06_Michigan_Quinnipiac",
         "Thursday",
         "2022"
        ],
        [
         "53651",
         "4/8/2023",
         "NCAA Tournament (at Amalie Arena, Tampa, Fla.)",
         "Quinnipiac",
         "/reports/team/Quinnipiac/47",
         "3",
         "Minnesota",
         "/reports/team/Minnesota/34",
         "2",
         "ot",
         "National Championship",
         "2023-04-08_Quinnipiac_Minnesota",
         "Saturday",
         "2022"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Conference</th>\n",
       "      <th>Home_Team</th>\n",
       "      <th>Home_Team_Link</th>\n",
       "      <th>Home_Score</th>\n",
       "      <th>Away_Team</th>\n",
       "      <th>Away_Team_Link</th>\n",
       "      <th>Away_Score</th>\n",
       "      <th>OT</th>\n",
       "      <th>Game_Notes</th>\n",
       "      <th>Game_ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Season_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53647</th>\n",
       "      <td>3/26/2023</td>\n",
       "      <td>NCAA Tournament, Bridgeport Regional (at Total...</td>\n",
       "      <td>Ohio State</td>\n",
       "      <td>/reports/team/Ohio-State/44</td>\n",
       "      <td>1</td>\n",
       "      <td>Quinnipiac</td>\n",
       "      <td>/reports/team/Quinnipiac/47</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bridgeport Regional Final</td>\n",
       "      <td>2023-03-26_Ohio State_Quinnipiac</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53648</th>\n",
       "      <td>3/26/2023</td>\n",
       "      <td>NCAA Tournament, Allentown Regional (at PPL Ce...</td>\n",
       "      <td>Penn State</td>\n",
       "      <td>/reports/team/Penn-State/60</td>\n",
       "      <td>1</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>/reports/team/Michigan/31</td>\n",
       "      <td>2</td>\n",
       "      <td>ot</td>\n",
       "      <td>Allentown Regional Final</td>\n",
       "      <td>2023-03-26_Penn State_Michigan</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53649</th>\n",
       "      <td>4/6/2023</td>\n",
       "      <td>NCAA Tournament (at Amalie Arena, Tampa, Fla.)</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>/reports/team/Boston-University/10</td>\n",
       "      <td>2</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>/reports/team/Minnesota/34</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National Semifinal</td>\n",
       "      <td>2023-04-06_Boston University_Minnesota</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53650</th>\n",
       "      <td>4/6/2023</td>\n",
       "      <td>NCAA Tournament (at Amalie Arena, Tampa, Fla.)</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>/reports/team/Michigan/31</td>\n",
       "      <td>2</td>\n",
       "      <td>Quinnipiac</td>\n",
       "      <td>/reports/team/Quinnipiac/47</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National Semifinal</td>\n",
       "      <td>2023-04-06_Michigan_Quinnipiac</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53651</th>\n",
       "      <td>4/8/2023</td>\n",
       "      <td>NCAA Tournament (at Amalie Arena, Tampa, Fla.)</td>\n",
       "      <td>Quinnipiac</td>\n",
       "      <td>/reports/team/Quinnipiac/47</td>\n",
       "      <td>3</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>/reports/team/Minnesota/34</td>\n",
       "      <td>2</td>\n",
       "      <td>ot</td>\n",
       "      <td>National Championship</td>\n",
       "      <td>2023-04-08_Quinnipiac_Minnesota</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date                                         Conference  \\\n",
       "53647  3/26/2023  NCAA Tournament, Bridgeport Regional (at Total...   \n",
       "53648  3/26/2023  NCAA Tournament, Allentown Regional (at PPL Ce...   \n",
       "53649   4/6/2023     NCAA Tournament (at Amalie Arena, Tampa, Fla.)   \n",
       "53650   4/6/2023     NCAA Tournament (at Amalie Arena, Tampa, Fla.)   \n",
       "53651   4/8/2023     NCAA Tournament (at Amalie Arena, Tampa, Fla.)   \n",
       "\n",
       "               Home_Team                      Home_Team_Link  Home_Score  \\\n",
       "53647         Ohio State         /reports/team/Ohio-State/44           1   \n",
       "53648         Penn State         /reports/team/Penn-State/60           1   \n",
       "53649  Boston University  /reports/team/Boston-University/10           2   \n",
       "53650           Michigan           /reports/team/Michigan/31           2   \n",
       "53651         Quinnipiac         /reports/team/Quinnipiac/47           3   \n",
       "\n",
       "        Away_Team               Away_Team_Link  Away_Score   OT  \\\n",
       "53647  Quinnipiac  /reports/team/Quinnipiac/47           4  NaN   \n",
       "53648    Michigan    /reports/team/Michigan/31           2   ot   \n",
       "53649   Minnesota   /reports/team/Minnesota/34           6  NaN   \n",
       "53650  Quinnipiac  /reports/team/Quinnipiac/47           5  NaN   \n",
       "53651   Minnesota   /reports/team/Minnesota/34           2   ot   \n",
       "\n",
       "                      Game_Notes                                 Game_ID  \\\n",
       "53647  Bridgeport Regional Final        2023-03-26_Ohio State_Quinnipiac   \n",
       "53648   Allentown Regional Final          2023-03-26_Penn State_Michigan   \n",
       "53649         National Semifinal  2023-04-06_Boston University_Minnesota   \n",
       "53650         National Semifinal          2023-04-06_Michigan_Quinnipiac   \n",
       "53651      National Championship         2023-04-08_Quinnipiac_Minnesota   \n",
       "\n",
       "            Day  Season_Year  \n",
       "53647    Sunday         2022  \n",
       "53648    Sunday         2022  \n",
       "53649  Thursday         2022  \n",
       "53650  Thursday         2022  \n",
       "53651  Saturday         2022  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all time table thru 2023\n",
    "df_thru_2023 = pd.read_csv(\"../data/tables/results_all_time_thru_2023.csv\")\n",
    "\n",
    "# check the dataframe\n",
    "df_thru_2023.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f51e02fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the new dataframe into the all time dataframe\n",
    "df_all_time = pd.concat([df_thru_2023, df_new], axis=0)\n",
    "\n",
    "# Check and normalize the column data types\n",
    "df_all_time = df_all_time.convert_dtypes()\n",
    "\n",
    "# save to CSV\n",
    "df_all_time.to_csv(\"../data/tables/results_all_time.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "202c29db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "Conference",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "Home_Team",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "Home_Team_Link",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "Home_Score",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Away_Team",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "Away_Team_Link",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "Away_Score",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "OT",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "Game_Notes",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "Game_ID",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "Day",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "Season_Year",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "Box_Link",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "Metrics_Link",
         "rawType": "string",
         "type": "string"
        }
       ],
       "ref": "32b5bb7f-268f-4295-96c9-69329139becd",
       "rows": [
        [
         "1225",
         "2025-03-30",
         "NCAA Tournament, Allentown Regional (at PPL Center, Allentown, Pa.)",
         "Penn State",
         "/reports/team/Penn-State/60",
         "3",
         "Connecticut",
         "/reports/team/Connecticut/17",
         "2",
         "ot",
         "Allentown Regional Final",
         "2025-03-30-Penn State-Connecticut",
         "Sunday",
         null,
         "/box/final/20250330/psu/con/",
         "/box/metrics.php?gd=103968"
        ],
        [
         "1226",
         "2025-03-30",
         "NCAA Tournament, Manchester Regional (at SNHU Arena, Manchester, N.H.)",
         "Boston College",
         "/reports/team/Boston-College/9",
         "1",
         "Denver",
         "/reports/team/Denver/20",
         "3",
         "",
         "Manchester Regional Final",
         "2025-03-30-Boston College-Denver",
         "Sunday",
         null,
         "/box/final/20250330/bc_/den/",
         "/box/metrics.php?gd=103977"
        ],
        [
         "1227",
         "2025-04-10",
         "NCAA Tournament (at Enterprise Center, St. Louis, Mo.)",
         "Denver",
         "/reports/team/Denver/20",
         "2",
         "Western Michigan",
         "/reports/team/Western-Michigan/57",
         "3",
         "2ot",
         "National Semifinal",
         "2025-04-10-Denver-Western Michigan",
         "Thursday",
         null,
         "/box/final/20250410/den/wmu/",
         "/box/metrics.php?gd=103978"
        ],
        [
         "1228",
         "2025-04-10",
         "NCAA Tournament (at Enterprise Center, St. Louis, Mo.)",
         "Boston University",
         "/reports/team/Boston-University/10",
         "3",
         "Penn State",
         "/reports/team/Penn-State/60",
         "1",
         "",
         "National Semifinal",
         "2025-04-10-Boston University-Penn State",
         "Thursday",
         null,
         "/box/final/20250410/bu_/psu/",
         "/box/metrics.php?gd=103979"
        ],
        [
         "1229",
         "2025-04-12",
         "NCAA Tournament (at Enterprise Center, St. Louis, Mo.)",
         "Western Michigan",
         "/reports/team/Western-Michigan/57",
         "6",
         "Boston University",
         "/reports/team/Boston-University/10",
         "2",
         "",
         "National Championship",
         "2025-04-12-Western Michigan-Boston University",
         "Saturday",
         null,
         "/box/final/20250412/wmu/bu_/",
         "/box/metrics.php?gd=103980"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Conference</th>\n",
       "      <th>Home_Team</th>\n",
       "      <th>Home_Team_Link</th>\n",
       "      <th>Home_Score</th>\n",
       "      <th>Away_Team</th>\n",
       "      <th>Away_Team_Link</th>\n",
       "      <th>Away_Score</th>\n",
       "      <th>OT</th>\n",
       "      <th>Game_Notes</th>\n",
       "      <th>Game_ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Season_Year</th>\n",
       "      <th>Box_Link</th>\n",
       "      <th>Metrics_Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>2025-03-30</td>\n",
       "      <td>NCAA Tournament, Allentown Regional (at PPL Ce...</td>\n",
       "      <td>Penn State</td>\n",
       "      <td>/reports/team/Penn-State/60</td>\n",
       "      <td>3</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>/reports/team/Connecticut/17</td>\n",
       "      <td>2</td>\n",
       "      <td>ot</td>\n",
       "      <td>Allentown Regional Final</td>\n",
       "      <td>2025-03-30-Penn State-Connecticut</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>/box/final/20250330/psu/con/</td>\n",
       "      <td>/box/metrics.php?gd=103968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>2025-03-30</td>\n",
       "      <td>NCAA Tournament, Manchester Regional (at SNHU ...</td>\n",
       "      <td>Boston College</td>\n",
       "      <td>/reports/team/Boston-College/9</td>\n",
       "      <td>1</td>\n",
       "      <td>Denver</td>\n",
       "      <td>/reports/team/Denver/20</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>Manchester Regional Final</td>\n",
       "      <td>2025-03-30-Boston College-Denver</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>/box/final/20250330/bc_/den/</td>\n",
       "      <td>/box/metrics.php?gd=103977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>NCAA Tournament (at Enterprise Center, St. Lou...</td>\n",
       "      <td>Denver</td>\n",
       "      <td>/reports/team/Denver/20</td>\n",
       "      <td>2</td>\n",
       "      <td>Western Michigan</td>\n",
       "      <td>/reports/team/Western-Michigan/57</td>\n",
       "      <td>3</td>\n",
       "      <td>2ot</td>\n",
       "      <td>National Semifinal</td>\n",
       "      <td>2025-04-10-Denver-Western Michigan</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>/box/final/20250410/den/wmu/</td>\n",
       "      <td>/box/metrics.php?gd=103978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>NCAA Tournament (at Enterprise Center, St. Lou...</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>/reports/team/Boston-University/10</td>\n",
       "      <td>3</td>\n",
       "      <td>Penn State</td>\n",
       "      <td>/reports/team/Penn-State/60</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>National Semifinal</td>\n",
       "      <td>2025-04-10-Boston University-Penn State</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>/box/final/20250410/bu_/psu/</td>\n",
       "      <td>/box/metrics.php?gd=103979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>NCAA Tournament (at Enterprise Center, St. Lou...</td>\n",
       "      <td>Western Michigan</td>\n",
       "      <td>/reports/team/Western-Michigan/57</td>\n",
       "      <td>6</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>/reports/team/Boston-University/10</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>National Championship</td>\n",
       "      <td>2025-04-12-Western Michigan-Boston University</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>/box/final/20250412/wmu/bu_/</td>\n",
       "      <td>/box/metrics.php?gd=103980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date                                         Conference  \\\n",
       "1225  2025-03-30  NCAA Tournament, Allentown Regional (at PPL Ce...   \n",
       "1226  2025-03-30  NCAA Tournament, Manchester Regional (at SNHU ...   \n",
       "1227  2025-04-10  NCAA Tournament (at Enterprise Center, St. Lou...   \n",
       "1228  2025-04-10  NCAA Tournament (at Enterprise Center, St. Lou...   \n",
       "1229  2025-04-12  NCAA Tournament (at Enterprise Center, St. Lou...   \n",
       "\n",
       "              Home_Team                      Home_Team_Link Home_Score  \\\n",
       "1225         Penn State         /reports/team/Penn-State/60          3   \n",
       "1226     Boston College      /reports/team/Boston-College/9          1   \n",
       "1227             Denver             /reports/team/Denver/20          2   \n",
       "1228  Boston University  /reports/team/Boston-University/10          3   \n",
       "1229   Western Michigan   /reports/team/Western-Michigan/57          6   \n",
       "\n",
       "              Away_Team                      Away_Team_Link Away_Score   OT  \\\n",
       "1225        Connecticut        /reports/team/Connecticut/17          2   ot   \n",
       "1226             Denver             /reports/team/Denver/20          3        \n",
       "1227   Western Michigan   /reports/team/Western-Michigan/57          3  2ot   \n",
       "1228         Penn State         /reports/team/Penn-State/60          1        \n",
       "1229  Boston University  /reports/team/Boston-University/10          2        \n",
       "\n",
       "                     Game_Notes  \\\n",
       "1225   Allentown Regional Final   \n",
       "1226  Manchester Regional Final   \n",
       "1227         National Semifinal   \n",
       "1228         National Semifinal   \n",
       "1229      National Championship   \n",
       "\n",
       "                                            Game_ID       Day  Season_Year  \\\n",
       "1225              2025-03-30-Penn State-Connecticut    Sunday         <NA>   \n",
       "1226               2025-03-30-Boston College-Denver    Sunday         <NA>   \n",
       "1227             2025-04-10-Denver-Western Michigan  Thursday         <NA>   \n",
       "1228        2025-04-10-Boston University-Penn State  Thursday         <NA>   \n",
       "1229  2025-04-12-Western Michigan-Boston University  Saturday         <NA>   \n",
       "\n",
       "                          Box_Link                Metrics_Link  \n",
       "1225  /box/final/20250330/psu/con/  /box/metrics.php?gd=103968  \n",
       "1226  /box/final/20250330/bc_/den/  /box/metrics.php?gd=103977  \n",
       "1227  /box/final/20250410/den/wmu/  /box/metrics.php?gd=103978  \n",
       "1228  /box/final/20250410/bu_/psu/  /box/metrics.php?gd=103979  \n",
       "1229  /box/final/20250412/wmu/bu_/  /box/metrics.php?gd=103980  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_time.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e083bf7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09d8892f",
   "metadata": {},
   "source": [
    "# Below FIRST DRAFT - POC - All Time Games above below 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "847c75d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbanc\\AppData\\Local\\Temp\\ipykernel_22516\\2933784045.py:97: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  summary = timeline.groupby('team_id').apply(team_summary).reset_index()\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1) Load & normalize ---\n",
    "\n",
    "all_time_path = os.path.join(\"..\", \"data\", \"tables\", \"results_all_time_thru_2023.csv\")\n",
    "DATA_PATH = all_time_path\n",
    "\n",
    "df = pd.read_csv(all_time_path)\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df['Home_Score'] = pd.to_numeric(df['Home_Score'], errors='coerce').astype('Int64')\n",
    "df['Away_Score'] = pd.to_numeric(df['Away_Score'], errors='coerce').astype('Int64')\n",
    "df['OT'] = df['OT'].astype(str).str.lower().replace({'nan':''})\n",
    "df['Game_Notes'] = df['Game_Notes'].astype(str).str.lower()\n",
    "\n",
    "def extract_id(s):\n",
    "    m = re.search(r\"/reports/team/.+?/(\\d+)\", str(s))\n",
    "    return int(m.group(1)) if m else pd.NA\n",
    "\n",
    "df['Home_Team_ID'] = df['Home_Team_Link'].apply(extract_id)\n",
    "df['Away_Team_ID'] = df['Away_Team_Link'].apply(extract_id)\n",
    "\n",
    "# --- 2) Filter what counts ---\n",
    "mask_both_teams = df['Home_Team_ID'].notna() & df['Away_Team_ID'].notna()\n",
    "mask_exhib = df['Game_Notes'].str.contains('exhib', na=False)\n",
    "mask_cancel = df['Game_Notes'].str.contains('cancel', na=False)\n",
    "df = df[mask_both_teams & ~mask_exhib & ~mask_cancel].copy()\n",
    "\n",
    "# --- 3) Explode to long ---\n",
    "home = df.rename(columns={\n",
    "    'Home_Team':'team','Home_Team_ID':'team_id','Home_Score':'team_score',\n",
    "    'Away_Team':'opp','Away_Team_ID':'opp_id','Away_Score':'opp_score'\n",
    "}).assign(venue='H')\n",
    "away = df.rename(columns={\n",
    "    'Away_Team':'team','Away_Team_ID':'team_id','Away_Score':'team_score',\n",
    "    'Home_Team':'opp','Home_Team_ID':'opp_id','Home_Score':'opp_score'\n",
    "}).assign(venue='A')\n",
    "\n",
    "long = pd.concat([home, away], ignore_index=True)\n",
    "\n",
    "keep_cols = ['Date','Season_Year','Game_ID','team','team_id','opp','opp_id',\n",
    "             'team_score','opp_score','venue','OT','Conference','Game_Notes']\n",
    "long = long[keep_cols].copy()\n",
    "\n",
    "# --- 4) Outcome & increment ---\n",
    "long['result'] = np.select(\n",
    "    [long['team_score'] > long['opp_score'],\n",
    "     long['team_score'] < long['opp_score']],\n",
    "    ['W','L'],\n",
    "    default='T'\n",
    ")\n",
    "long['is_win']  = (long['result']=='W').astype(int)\n",
    "long['is_loss'] = (long['result']=='L').astype(int)\n",
    "long['is_tie']  = (long['result']=='T').astype(int)\n",
    "\n",
    "# For the .500 curve: ties are neutral\n",
    "long['delta'] = long['is_win'] - long['is_loss']  # +1 / -1 / 0\n",
    "\n",
    "# --- 5) Sort & sequence ---\n",
    "long = long.sort_values(['team_id','Date','Game_ID'], kind='mergesort')\n",
    "long['gp'] = long.groupby('team_id').cumcount() + 1\n",
    "\n",
    "# --- 6) Cumulative record & games above .500 ---\n",
    "long['cum_w'] = long.groupby('team_id')['is_win'].cumsum()\n",
    "long['cum_l'] = long.groupby('team_id')['is_loss'].cumsum()\n",
    "long['cum_t'] = long.groupby('team_id')['is_tie'].cumsum()\n",
    "long['games_above_500'] = long['cum_w'] - long['cum_l']\n",
    "long['record_str'] = long['cum_w'].astype(str)+'-'+long['cum_l'].astype(str)+'-'+long['cum_t'].astype(str)\n",
    "\n",
    "timeline = long[['team_id','team','Date','Game_ID','Season_Year','gp',\n",
    "                 'result','delta','cum_w','cum_l','cum_t','games_above_500']].copy()\n",
    "\n",
    "# --- 7) Milestones for annotations ---\n",
    "def team_summary(g):\n",
    "    g = g.sort_values('Date')\n",
    "    max_idx = g['games_above_500'].idxmax()\n",
    "    min_idx = g['games_above_500'].idxmin()\n",
    "    out = {\n",
    "        'team': g['team'].iloc[0],\n",
    "        'first_date': g['Date'].min(),\n",
    "        'last_date': g['Date'].max(),\n",
    "        'max_point': g.loc[max_idx, 'games_above_500'],\n",
    "        'max_date': g.loc[max_idx, 'Date'],\n",
    "        'min_point': g.loc[min_idx, 'games_above_500'],\n",
    "        'min_date': g.loc[min_idx, 'Date'],\n",
    "        'final_w': g['cum_w'].iloc[-1],\n",
    "        'final_l': g['cum_l'].iloc[-1],\n",
    "        'final_t': g['cum_t'].iloc[-1],\n",
    "    }\n",
    "    # last time exactly at .500 (if ever)\n",
    "    at500 = g[g['games_above_500']==0]\n",
    "    out['last_500_date'] = at500['Date'].iloc[-1] if not at500.empty else pd.NaT\n",
    "    return pd.Series(out)\n",
    "\n",
    "summary = timeline.groupby('team_id').apply(team_summary).reset_index()\n",
    "\n",
    "# --- 8) Save for plotting ---\n",
    "timeline.to_parquet('team_timeseries.parquet', index=False)\n",
    "summary.to_parquet('team_summary.parquet', index=False)\n",
    "# (or .csv if you prefer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6033d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbanc\\AppData\\Local\\Temp\\ipykernel_22516\\1220221622.py:107: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  summary = timeline.groupby(\"team_id\", group_keys=False).apply(summarize).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Files created in /mnt/data:\n",
      "- team_timeseries.parquet  |  team_timeseries.csv\n",
      "- team_summary.parquet     |  team_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Re-run full pipeline (concise version) and save outputs, avoiding any UI display calls.\n",
    "\n",
    "import re, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# DATA_PATH = Path(\"/mnt/data/results_table_all_time_thru 2023.csv\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "def find_col(possible, cols):\n",
    "    norm = {c.lower().replace(\" \", \"_\"): c for c in cols}\n",
    "    for p in possible:\n",
    "        key = p.lower().replace(\" \", \"_\")\n",
    "        if key in norm: return norm[key]\n",
    "    return None\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "c_date   = find_col([\"Date\"], cols)\n",
    "c_season = find_col([\"Season_Year\",\"Season\",\"Season Year\"], cols)\n",
    "c_gmid   = find_col([\"Game_ID\",\"GameID\",\"Game Id\",\"gid\"], cols)\n",
    "c_htm    = find_col([\"Home_Team\",\"Home Team\",\"Home\"], cols)\n",
    "c_atm    = find_col([\"Away_Team\",\"Away Team\",\"Away\",\"Visitor_Team\",\"Visitor Team\"], cols)\n",
    "c_hsc    = find_col([\"Home_Score\",\"Home Score\",\"HomeGoals\",\"Home_Goals\"], cols)\n",
    "c_asc    = find_col([\"Away_Score\",\"Away Score\",\"AwayGoals\",\"Away_Goals\"], cols)\n",
    "c_ot     = find_col([\"OT\",\"OT_SO\",\"OT/SO\",\"Overtime\",\"Shootout\"], cols)\n",
    "c_notes  = find_col([\"Game_Notes\",\"Notes\",\"Game Notes\"], cols)\n",
    "c_hlnk   = find_col([\"Home_Team_Link\",\"Home Team Link\",\"Home_Link\"], cols)\n",
    "c_alnk   = find_col([\"Away_Team_Link\",\"Away Team Link\",\"Away_Link\"], cols)\n",
    "\n",
    "df[c_date] = pd.to_datetime(df[c_date], errors=\"coerce\")\n",
    "if c_season is None:\n",
    "    c_season=\"__Season_Fallback__\"; df[c_season]=df[c_date].dt.year\n",
    "if c_gmid is None:\n",
    "    c_gmid=\"__GameID_Fallback__\"; df[c_gmid]=np.arange(1,len(df)+1)\n",
    "if c_hsc: df[c_hsc]=pd.to_numeric(df[c_hsc], errors=\"coerce\").astype(\"Int64\")\n",
    "if c_asc: df[c_asc]=pd.to_numeric(df[c_asc], errors=\"coerce\").astype(\"Int64\")\n",
    "if c_ot: df[c_ot]=df[c_ot].astype(str).str.lower()\n",
    "if c_notes: df[c_notes]=df[c_notes].astype(str).str.lower()\n",
    "\n",
    "def extract_team_id(u):\n",
    "    if pd.isna(u): return pd.NA\n",
    "    m=re.search(r\"/reports/team/.+?/(\\d+)\", str(u))\n",
    "    return int(m.group(1)) if m else pd.NA\n",
    "\n",
    "if c_hlnk and c_alnk:\n",
    "    df[\"Home_Team_ID\"]=df[c_hlnk].apply(extract_team_id)\n",
    "    df[\"Away_Team_ID\"]=df[c_alnk].apply(extract_team_id)\n",
    "else:\n",
    "    df[\"Home_Team_ID\"]=df[c_htm].astype(str).str.strip().str.lower().map(lambda s: abs(hash(s))%(10**9))\n",
    "    df[\"Away_Team_ID\"]=df[c_atm].astype(str).str.strip().str.lower().map(lambda s: abs(hash(s))%(10**9))\n",
    "\n",
    "mask_valid = df[\"Home_Team_ID\"].notna() & df[\"Away_Team_ID\"].notna()\n",
    "mask_exhib = df[c_notes].str.contains(\"exhib\", na=False) if c_notes else False\n",
    "mask_cancel= df[c_notes].str.contains(\"cancel\",na=False) if c_notes else False\n",
    "df = df[mask_valid & ~mask_exhib & ~mask_cancel].copy()\n",
    "\n",
    "home = df.rename(columns={\n",
    "    c_date:\"Date\", c_season:\"Season_Year\", c_gmid:\"Game_ID\",\n",
    "    c_htm:\"team\",\"Home_Team_ID\":\"team_id\", c_hsc:\"team_score\",\n",
    "    c_atm:\"opp\",\"Away_Team_ID\":\"opp_id\", c_asc:\"opp_score\",\n",
    "    **({c_ot:\"OT\"} if c_ot else {}), **({c_notes:\"Game_Notes\"} if c_notes else {})\n",
    "})[[\"Date\",\"Season_Year\",\"Game_ID\",\"team\",\"team_id\",\"team_score\",\"opp\",\"opp_id\",\"opp_score\"] + ([\"OT\"] if c_ot else []) + ([\"Game_Notes\"] if c_notes else [])]\n",
    "home[\"venue\"]=\"H\"\n",
    "\n",
    "away = df.rename(columns={\n",
    "    c_date:\"Date\", c_season:\"Season_Year\", c_gmid:\"Game_ID\",\n",
    "    c_atm:\"team\",\"Away_Team_ID\":\"team_id\", c_asc:\"team_score\",\n",
    "    c_htm:\"opp\",\"Home_Team_ID\":\"opp_id\", c_hsc:\"opp_score\",\n",
    "    **({c_ot:\"OT\"} if c_ot else {}), **({c_notes:\"Game_Notes\"} if c_notes else {})\n",
    "})[[\"Date\",\"Season_Year\",\"Game_ID\",\"team\",\"team_id\",\"team_score\",\"opp\",\"opp_id\",\"opp_score\"] + ([\"OT\"] if c_ot else []) + ([\"Game_Notes\"] if c_notes else [])]\n",
    "away[\"venue\"]=\"A\"\n",
    "\n",
    "long=pd.concat([home,away], ignore_index=True)\n",
    "long=long[long[\"team_score\"].notna() & long[\"opp_score\"].notna()].copy()\n",
    "\n",
    "long[\"result\"]=np.where(long[\"team_score\"]>long[\"opp_score\"],\"W\",np.where(long[\"team_score\"]<long[\"opp_score\"],\"L\",\"T\"))\n",
    "long[\"is_win\"]=(long[\"result\"]==\"W\").astype(int)\n",
    "long[\"is_loss\"]=(long[\"result\"]==\"L\").astype(int)\n",
    "long[\"is_tie\"]=(long[\"result\"]==\"T\").astype(int)\n",
    "long=long.sort_values([\"team_id\",\"Date\",\"Game_ID\"], kind=\"mergesort\")\n",
    "long[\"gp\"]=long.groupby(\"team_id\").cumcount()+1\n",
    "long[\"cum_w\"]=long.groupby(\"team_id\")[\"is_win\"].cumsum()\n",
    "long[\"cum_l\"]=long.groupby(\"team_id\")[\"is_loss\"].cumsum()\n",
    "long[\"cum_t\"]=long.groupby(\"team_id\")[\"is_tie\"].cumsum()\n",
    "long[\"games_above_500\"]=long[\"cum_w\"]-long[\"cum_l\"]\n",
    "long[\"delta\"]=long[\"is_win\"]-long[\"is_loss\"]\n",
    "\n",
    "timeline=long[[\"team_id\",\"team\",\"Date\",\"Game_ID\",\"Season_Year\",\"gp\",\"result\",\"delta\",\"cum_w\",\"cum_l\",\"cum_t\",\"games_above_500\",\"venue\"]].copy()\n",
    "\n",
    "def summarize(g):\n",
    "    g=g.sort_values(\"Date\")\n",
    "    at500=g[g[\"games_above_500\"]==0]\n",
    "    return pd.Series({\n",
    "        \"team\":g[\"team\"].iloc[0],\n",
    "        \"first_date\":g[\"Date\"].min(),\n",
    "        \"last_date\":g[\"Date\"].max(),\n",
    "        \"max_point\":g[\"games_above_500\"].max(),\n",
    "        \"max_date\":g.loc[g[\"games_above_500\"].idxmax(),\"Date\"],\n",
    "        \"min_point\":g[\"games_above_500\"].min(),\n",
    "        \"min_date\":g.loc[g[\"games_above_500\"].idxmin(),\"Date\"],\n",
    "        \"final_w\":g[\"cum_w\"].iloc[-1],\n",
    "        \"final_l\":g[\"cum_l\"].iloc[-1],\n",
    "        \"final_t\":g[\"cum_t\"].iloc[-1],\n",
    "        \"final_games_above_500\":g[\"games_above_500\"].iloc[-1],\n",
    "        \"last_500_date\": at500[\"Date\"].iloc[-1] if not at500.empty else pd.NaT,\n",
    "    })\n",
    "\n",
    "summary = timeline.groupby(\"team_id\", group_keys=False).apply(summarize).reset_index()\n",
    "\n",
    "out_dir=Path(\"../TEMP\")\n",
    "timeline.to_parquet(out_dir/\"team_timeseries.parquet\", index=False)\n",
    "summary.to_parquet(out_dir/\"team_summary.parquet\", index=False)\n",
    "timeline.to_csv(out_dir/\"team_timeseries.csv\", index=False)\n",
    "summary.to_csv(out_dir/\"team_summary.csv\", index=False)\n",
    "\n",
    "print(\"Done. Files created in /mnt/data:\")\n",
    "print(\"- team_timeseries.parquet  |  team_timeseries.csv\")\n",
    "print(\"- team_summary.parquet     |  team_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7a18b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "transform_games_to_team_timeseries.py\n",
    "\n",
    "Purpose\n",
    "-------\n",
    "Turn a \"one row per game\" college hockey CSV into:\n",
    "  1) a per-team, per-game time series with cumulative record and games-above-.500\n",
    "  2) a per-team summary for annotations (max/min points, last .500 date, final record)\n",
    "\n",
    "Key Decisions\n",
    "-------------\n",
    "- .500 curve uses the classic definition: +1 for a WIN, -1 for a LOSS, 0 for a TIE.\n",
    "- Ties do not move the line (they still appear in the cumulative record).\n",
    "- Exhibitions / cancellations are excluded if noted in the data.\n",
    "- If official team link IDs are missing, a stable hash of team names is used for `team_id`.\n",
    "\n",
    "Output\n",
    "------\n",
    "- team_timeseries.csv  : one row per team per game with 'games_above_500'\n",
    "- team_summary.csv     : per-team milestones for chart annotations\n",
    "\n",
    "Author: you + ChatGPT\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Optional, List\n",
    "\n",
    "# ---------- Utilities ---------------------------------------------------------\n",
    "\n",
    "def find_col(possible: List[str], cols: List[str]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Fuzzy column resolver: try common alternatives, tolerant to spaces/underscores/case.\n",
    "    Returns the first match found or None.\n",
    "    \"\"\"\n",
    "    norm = {c.lower().replace(\" \", \"_\"): c for c in cols}\n",
    "    for p in possible:\n",
    "        key = p.lower().replace(\" \", \"_\")\n",
    "        if key in norm:\n",
    "            return norm[key]\n",
    "    return None\n",
    "\n",
    "def extract_team_id(url_like) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    If your source has official team links, extract the numeric ID from a pattern like:\n",
    "      '/reports/team/<something>/<id>'\n",
    "    Returns NA if no match.\n",
    "    \"\"\"\n",
    "    if pd.isna(url_like):\n",
    "        return pd.NA\n",
    "    m = re.search(r\"/reports/team/.+?/(\\d+)\", str(url_like))\n",
    "    return int(m.group(1)) if m else pd.NA\n",
    "\n",
    "\n",
    "# ---------- Main transformation ----------------------------------------------\n",
    "\n",
    "def build_timeseries(input_csv: str, out_dir: str = \"./\") -> None:\n",
    "    out_path = Path(out_dir)\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Load & normalize ------------------------------------------------------\n",
    "    df_raw = pd.read_csv(input_csv)\n",
    "    cols = df_raw.columns.tolist()\n",
    "\n",
    "    c_date   = find_col([\"Date\"], cols)\n",
    "    c_season = find_col([\"Season_Year\",\"Season\",\"Season Year\"], cols)\n",
    "    c_gmid   = find_col([\"Game_ID\",\"GameID\",\"Game Id\",\"gid\"], cols)\n",
    "\n",
    "    c_htm    = find_col([\"Home_Team\",\"Home Team\",\"Home\"], cols)\n",
    "    c_atm    = find_col([\"Away_Team\",\"Away Team\",\"Away\",\"Visitor_Team\",\"Visitor Team\"], cols)\n",
    "    c_hsc    = find_col([\"Home_Score\",\"Home Score\",\"HomeGoals\",\"Home_Goals\"], cols)\n",
    "    c_asc    = find_col([\"Away_Score\",\"Away Score\",\"AwayGoals\",\"Away_Goals\"], cols)\n",
    "\n",
    "    c_ot     = find_col([\"OT\",\"OT_SO\",\"OT/SO\",\"Overtime\",\"Shootout\"], cols)\n",
    "    c_notes  = find_col([\"Game_Notes\",\"Notes\",\"Game Notes\"], cols)\n",
    "\n",
    "    c_hlnk   = find_col([\"Home_Team_Link\",\"Home Team Link\",\"Home_Link\"], cols)\n",
    "    c_alnk   = find_col([\"Away_Team_Link\",\"Away Team Link\",\"Away_Link\"], cols)\n",
    "\n",
    "    if c_date is None:\n",
    "        raise ValueError(\"No 'Date' column foundcannot build timelines.\")\n",
    "\n",
    "    df = df_raw.copy()\n",
    "    df[c_date] = pd.to_datetime(df[c_date], errors=\"coerce\")\n",
    "\n",
    "    if c_season is None:\n",
    "        # Simple fallback: use calendar year of the date.\n",
    "        c_season = \"__Season_Fallback__\"\n",
    "        df[c_season] = df[c_date].dt.year\n",
    "\n",
    "    if c_gmid is None:\n",
    "        # Stable fallback game_id if not supplied\n",
    "        c_gmid = \"__GameID_Fallback__\"\n",
    "        df[c_gmid] = np.arange(1, len(df) + 1)\n",
    "\n",
    "    # Scores\n",
    "    for score_col in [c_hsc, c_asc]:\n",
    "        if score_col is not None:\n",
    "            df[score_col] = pd.to_numeric(df[score_col], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # Text normalization\n",
    "    if c_ot is not None:\n",
    "        df[c_ot] = df[c_ot].astype(str).str.lower()\n",
    "    if c_notes is not None:\n",
    "        df[c_notes] = df[c_notes].astype(str).str.lower()\n",
    "\n",
    "    # 2) Team IDs --------------------------------------------------------------\n",
    "    # Prefer official IDs from link columns; otherwise, make a stable hash of team names.\n",
    "    if c_hlnk and c_alnk:\n",
    "        df[\"Home_Team_ID\"] = df[c_hlnk].apply(extract_team_id)\n",
    "        df[\"Away_Team_ID\"] = df[c_alnk].apply(extract_team_id)\n",
    "    else:\n",
    "        df[\"Home_Team_ID\"] = df[c_htm].astype(str).str.strip().str.lower().map(lambda s: abs(hash(s)) % (10**9))\n",
    "        df[\"Away_Team_ID\"] = df[c_atm].astype(str).str.strip().str.lower().map(lambda s: abs(hash(s)) % (10**9))\n",
    "\n",
    "    # 3) Filter what shouldnt count ------------------------------------------\n",
    "    mask_valid = df[\"Home_Team_ID\"].notna() & df[\"Away_Team_ID\"].notna()\n",
    "    if c_notes is not None:\n",
    "        mask_exhib  = df[c_notes].str.contains(\"exhib\",  na=False)\n",
    "        mask_cancel = df[c_notes].str.contains(\"cancel\", na=False)\n",
    "    else:\n",
    "        mask_exhib = mask_cancel = False\n",
    "\n",
    "    df = df[mask_valid & ~mask_exhib & ~mask_cancel].copy()\n",
    "\n",
    "    # 4) Explode to long (one row per team per game) --------------------------\n",
    "    home = df.rename(columns={\n",
    "        c_date:\"Date\", c_season:\"Season_Year\", c_gmid:\"Game_ID\",\n",
    "        c_htm:\"team\", \"Home_Team_ID\":\"team_id\", c_hsc:\"team_score\",\n",
    "        c_atm:\"opp\", \"Away_Team_ID\":\"opp_id\", c_asc:\"opp_score\",\n",
    "        **({c_ot:\"OT\"} if c_ot else {}), **({c_notes:\"Game_Notes\"} if c_notes else {}),\n",
    "    })\n",
    "    home = home[[\"Date\",\"Season_Year\",\"Game_ID\",\"team\",\"team_id\",\"team_score\",\"opp\",\"opp_id\",\"opp_score\"] +\n",
    "                ([\"OT\"] if c_ot else []) + ([\"Game_Notes\"] if c_notes else [])]\n",
    "    home[\"venue\"] = \"H\"\n",
    "\n",
    "    away = df.rename(columns={\n",
    "        c_date:\"Date\", c_season:\"Season_Year\", c_gmid:\"Game_ID\",\n",
    "        c_atm:\"team\", \"Away_Team_ID\":\"team_id\", c_asc:\"team_score\",\n",
    "        c_htm:\"opp\", \"Home_Team_ID\":\"opp_id\", c_hsc:\"opp_score\",\n",
    "        **({c_ot:\"OT\"} if c_ot else {}), **({c_notes:\"Game_Notes\"} if c_notes else {}),\n",
    "    })\n",
    "    away = away[[\"Date\",\"Season_Year\",\"Game_ID\",\"team\",\"team_id\",\"team_score\",\"opp\",\"opp_id\",\"opp_score\"] +\n",
    "                ([\"OT\"] if c_ot else []) + ([\"Game_Notes\"] if c_notes else [])]\n",
    "    away[\"venue\"] = \"A\"\n",
    "\n",
    "    long = pd.concat([home, away], ignore_index=True)\n",
    "\n",
    "    # Drop rows without scores (postponed/unplayed/etc.)\n",
    "    long = long[long[\"team_score\"].notna() & long[\"opp_score\"].notna()].copy()\n",
    "\n",
    "    # 5) Outcome & increment for the .500 curve --------------------------------\n",
    "    long[\"result\"]  = np.where(long[\"team_score\"] > long[\"opp_score\"], \"W\",\n",
    "                        np.where(long[\"team_score\"] < long[\"opp_score\"], \"L\", \"T\"))\n",
    "    long[\"is_win\"]  = (long[\"result\"] == \"W\").astype(int)\n",
    "    long[\"is_loss\"] = (long[\"result\"] == \"L\").astype(int)\n",
    "    long[\"is_tie\"]  = (long[\"result\"] == \"T\").astype(int)\n",
    "\n",
    "    # .500 line increment (ties = 0)\n",
    "    long[\"delta\"]   = long[\"is_win\"] - long[\"is_loss\"]\n",
    "\n",
    "    # 6) Order & per-team sequencing ------------------------------------------\n",
    "    long = long.sort_values([\"team_id\",\"Date\",\"Game_ID\"], kind=\"mergesort\")\n",
    "    long[\"gp\"] = long.groupby(\"team_id\").cumcount() + 1\n",
    "\n",
    "    # 7) Cumulative record & games-above-.500 ----------------------------------\n",
    "    long[\"cum_w\"] = long.groupby(\"team_id\")[\"is_win\"].cumsum()\n",
    "    long[\"cum_l\"] = long.groupby(\"team_id\")[\"is_loss\"].cumsum()\n",
    "    long[\"cum_t\"] = long.groupby(\"team_id\")[\"is_tie\"].cumsum()\n",
    "\n",
    "    # This is the Y-value for the chart\n",
    "    long[\"games_above_500\"] = long[\"cum_w\"] - long[\"cum_l\"]\n",
    "\n",
    "    # --- Goal Differential (GD) -----------------------------------------------\n",
    "    # Per-game goal differential from the *team's* perspective.\n",
    "    # For shootouts: most NCAA datasets store regulation+OT goals only (SO adds no goals),\n",
    "    # so this calculation should already be correct. If your table encodes SO winner goals,\n",
    "    # strip those first.\n",
    "    long[\"gd\"] = (long[\"team_score\"].astype(int) - long[\"opp_score\"].astype(int))\n",
    "\n",
    "    # Cumulative all-time GD: this is the Y-value for a GD curve (step-like, changes only on game days)\n",
    "    long[\"cum_gd\"] = long.groupby(\"team_id\")[\"gd\"].cumsum()\n",
    "\n",
    "\n",
    "    timeline = long[[\n",
    "        \"team_id\",\"team\",\"Date\",\"Game_ID\",\"Season_Year\",\"gp\",\n",
    "        \"team_score\",\"opp_score\",          # (optional but handy)\n",
    "        \"result\",\"delta\",                  # win/loss increment (for .500 curve)\n",
    "        \"gd\",\"cum_gd\",                     # <-- NEW: per-game and cumulative GD\n",
    "        \"cum_w\",\"cum_l\",\"cum_t\",\"games_above_500\",\n",
    "        \"venue\"\n",
    "    ]].copy()\n",
    "\n",
    "    # timeline = long[[\n",
    "    #     \"team_id\",\"team\",\"Date\",\"Game_ID\",\"Season_Year\",\"gp\",\n",
    "    #     \"result\",\"delta\",\"cum_w\",\"cum_l\",\"cum_t\",\"games_above_500\",\"venue\"\n",
    "    # ]].copy()\n",
    "\n",
    "    # 8) Per-team milestones (for annotations) --------------------------------\n",
    "    def summarize_team(g: pd.DataFrame) -> pd.Series:\n",
    "        g = g.sort_values(\"Date\")\n",
    "        at500 = g[g[\"games_above_500\"] == 0]\n",
    "\n",
    "        # Locate max/min cumulative GD rows\n",
    "        max_gd_idx = g[\"cum_gd\"].idxmax()\n",
    "        min_gd_idx = g[\"cum_gd\"].idxmin()\n",
    "\n",
    "        return pd.Series({\n",
    "            \"team\": g[\"team\"].iloc[0],\n",
    "            \"first_date\": g[\"Date\"].min(),\n",
    "            \"last_date\":  g[\"Date\"].max(),\n",
    "\n",
    "            # .500 curve milestones (you already had these)\n",
    "            \"max_point\":  g[\"games_above_500\"].max(),\n",
    "            \"max_date\":   g.loc[g[\"games_above_500\"].idxmax(),\"Date\"],\n",
    "            \"min_point\":  g[\"games_above_500\"].min(),\n",
    "            \"min_date\":   g.loc[g[\"games_above_500\"].idxmin(),\"Date\"],\n",
    "            \"final_w\":    g[\"cum_w\"].iloc[-1],\n",
    "            \"final_l\":    g[\"cum_l\"].iloc[-1],\n",
    "            \"final_t\":    g[\"cum_t\"].iloc[-1],\n",
    "            \"final_games_above_500\": g[\"games_above_500\"].iloc[-1],\n",
    "            \"last_500_date\": at500[\"Date\"].iloc[-1] if not at500.empty else pd.NaT,\n",
    "\n",
    "            # --- NEW: GD milestones\n",
    "            \"max_cum_gd\": g.loc[max_gd_idx, \"cum_gd\"],\n",
    "            \"max_cum_gd_date\": g.loc[max_gd_idx, \"Date\"],\n",
    "            \"min_cum_gd\": g.loc[min_gd_idx, \"cum_gd\"],\n",
    "            \"min_cum_gd_date\": g.loc[min_gd_idx, \"Date\"],\n",
    "            \"final_cum_gd\": g[\"cum_gd\"].iloc[-1],\n",
    "        })\n",
    "\n",
    "    # def summarize_team(g: pd.DataFrame) -> pd.Series:\n",
    "    #     g = g.sort_values(\"Date\")\n",
    "    #     at500 = g[g[\"games_above_500\"] == 0]\n",
    "    #     return pd.Series({\n",
    "    #         \"team\": g[\"team\"].iloc[0],\n",
    "    #         \"first_date\": g[\"Date\"].min(),\n",
    "    #         \"last_date\":  g[\"Date\"].max(),\n",
    "    #         \"max_point\":  g[\"games_above_500\"].max(),\n",
    "    #         \"max_date\":   g.loc[g[\"games_above_500\"].idxmax(),\"Date\"],\n",
    "    #         \"min_point\":  g[\"games_above_500\"].min(),\n",
    "    #         \"min_date\":   g.loc[g[\"games_above_500\"].idxmin(),\"Date\"],\n",
    "    #         \"final_w\":    g[\"cum_w\"].iloc[-1],\n",
    "    #         \"final_l\":    g[\"cum_l\"].iloc[-1],\n",
    "    #         \"final_t\":    g[\"cum_t\"].iloc[-1],\n",
    "    #         \"final_games_above_500\": g[\"games_above_500\"].iloc[-1],\n",
    "    #         \"last_500_date\": at500[\"Date\"].iloc[-1] if not at500.empty else pd.NaT,\n",
    "    #     })\n",
    "\n",
    "    summary = timeline.groupby(\"team_id\", group_keys=False).apply(summarize_team).reset_index()\n",
    "\n",
    "    # 9) Save outputs (CSV by default; Parquet lines are included if you have pyarrow) ----\n",
    "    timeline.to_csv(out_path / \"../TEMP/team_timeseries.csv\", index=False)\n",
    "    summary.to_csv(out_path / \"../TEMP/team_summary.csv\", index=False)\n",
    "\n",
    "    # If you prefer Parquet (faster; needs pyarrow or fastparquet):\n",
    "    # timeline.to_parquet(out_path / \"team_timeseries.parquet\", index=False)\n",
    "    # summary.to_parquet(out_path / \"team_summary.parquet\", index=False)\n",
    "\n",
    "\n",
    "# ---------- Optional: simple plotting helper ---------------------------------\n",
    "# (Keeps colors/style up to you; this just draws a step-like line.)\n",
    "def plot_team_curve(timeline: pd.DataFrame, team_name_or_id):\n",
    "    \"\"\"\n",
    "    Example usage:\n",
    "        tl = pd.read_csv(\"team_timeseries.csv\", parse_dates=[\"Date\"])\n",
    "        plot_team_curve(tl, team_name_or_id=123456789)  # or a team name string\n",
    "\n",
    "    This produces a basic line of `games_above_500` vs. date.\n",
    "    Add your own shading/annotations to mimic the NHL-style chart.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    if isinstance(team_name_or_id, (int, np.integer)):\n",
    "        g = timeline[timeline[\"team_id\"] == team_name_or_id].copy()\n",
    "        label = str(team_name_or_id)\n",
    "    else:\n",
    "        g = timeline[timeline[\"team\"].str.casefold() == str(team_name_or_id).casefold()].copy()\n",
    "        label = str(team_name_or_id)\n",
    "\n",
    "    g = g.sort_values(\"Date\")\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.plot(g[\"Date\"], g[\"games_above_500\"], linewidth=1.25, label=label)\n",
    "    plt.axhline(0, linewidth=1)\n",
    "    plt.xlabel(\"Date\"); plt.ylabel(\"Games Above/Below .500\")\n",
    "    plt.title(f\"{g['team'].iloc[0] if not g.empty else label}: Historical Performance\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# # ---------- Run from a notebook/script ---------------------------------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     build_timeseries(DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "797a4f2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing column provided to 'parse_dates': 'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Reload & filter (idempotent)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m tl \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../TEMP/team_summary.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m team_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvidence\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m g \u001b[38;5;241m=\u001b[39m tl[tl[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteam\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcasefold() \u001b[38;5;241m==\u001b[39m team_name\u001b[38;5;241m.\u001b[39mcasefold()]\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:161\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_usecols_names(\n\u001b[0;32m    156\u001b[0m             usecols,\n\u001b[0;32m    157\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    158\u001b[0m         )\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_parse_dates_presence\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_noconvert_columns()\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:243\u001b[0m, in \u001b[0;36mParserBase._validate_parse_dates_presence\u001b[1;34m(self, columns)\u001b[0m\n\u001b[0;32m    233\u001b[0m missing_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m    235\u001b[0m         {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    240\u001b[0m     )\n\u001b[0;32m    241\u001b[0m )\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_cols:\n\u001b[1;32m--> 243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing column provided to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_dates\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    245\u001b[0m     )\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# Convert positions to actual column names\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    248\u001b[0m     col \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns) \u001b[38;5;28;01melse\u001b[39;00m columns[col]\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols_needed\n\u001b[0;32m    250\u001b[0m ]\n",
      "\u001b[1;31mValueError\u001b[0m: Missing column provided to 'parse_dates': 'Date'"
     ]
    }
   ],
   "source": [
    "# Create a plot of a team\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Reload & filter (idempotent)\n",
    "tl = pd.read_csv(Path(\"../TEMP/team_summary.csv\"), parse_dates=[\"Date\"])\n",
    "team_name = \"Providence\"\n",
    "g = tl[tl[\"team\"].str.casefold() == team_name.casefold()].copy().sort_values(\"Date\")\n",
    "\n",
    "# Convert to numpy-friendly arrays\n",
    "x_vals = g[\"Date\"].values\n",
    "y_vals = g[\"games_above_500\"].astype(float).values  # ensure numeric dtype\n",
    "\n",
    "# Milestones\n",
    "max_idx = int(np.nanargmax(y_vals))\n",
    "min_idx = int(np.nanargmin(y_vals))\n",
    "last_500 = g[g[\"games_above_500\"] == 0][\"Date\"].max()\n",
    "\n",
    "final_w = int(g[\"cum_w\"].iloc[-1])\n",
    "final_l = int(g[\"cum_l\"].iloc[-1])\n",
    "final_t = int(g[\"cum_t\"].iloc[-1])\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.step(x_vals, y_vals, where=\"post\", linewidth=1.5, label=team_name)\n",
    "\n",
    "# Shade above/below zero using default colors\n",
    "plt.fill_between(x_vals, 0.0, y_vals, where=y_vals>0, alpha=0.2, step=\"post\")\n",
    "plt.fill_between(x_vals, 0.0, y_vals, where=y_vals<0, alpha=0.2, step=\"post\")\n",
    "\n",
    "plt.axhline(0.0, linewidth=1)\n",
    "\n",
    "# Annotations\n",
    "plt.plot(x_vals[max_idx], y_vals[max_idx], marker=\"o\")\n",
    "plt.annotate(\n",
    "    f\"Highest: {int(y_vals[max_idx])}\\n{pd.to_datetime(x_vals[max_idx]).date()}\",\n",
    "    (x_vals[max_idx], y_vals[max_idx]), xytext=(10, 10), textcoords=\"offset points\"\n",
    ")\n",
    "plt.plot(x_vals[min_idx], y_vals[min_idx], marker=\"o\")\n",
    "plt.annotate(\n",
    "    f\"Lowest: {int(y_vals[min_idx])}\\n{pd.to_datetime(x_vals[min_idx]).date()}\",\n",
    "    (x_vals[min_idx], y_vals[min_idx]), xytext=(10, -20), textcoords=\"offset points\"\n",
    ")\n",
    "if pd.notna(last_500):\n",
    "    last_val = float(g.loc[g[\"Date\"] == last_500, \"games_above_500\"].iloc[-1])\n",
    "    plt.plot(last_500, last_val, marker=\"o\")\n",
    "    plt.annotate(f\"Last .500: {last_500.date()}\", (last_500, last_val),\n",
    "                 xytext=(10, 10), textcoords=\"offset points\")\n",
    "\n",
    "plt.title(f\"{team_name}: Games Above/Below .500 Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Games Above/Below .500\")\n",
    "\n",
    "final_str = f\"Final Record: {final_w}-{final_l}-{final_t}  ( {final_w - final_l})\"\n",
    "plt.gcf().text(0.99, 0.02, final_str, ha=\"right\", va=\"bottom\", bbox=dict(boxstyle=\"round,pad=0.3\"))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902e219f",
   "metadata": {},
   "source": [
    "## All Time Goal Differential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672fa6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Goal Differential (GD) -----------------------------------------------\n",
    "# # Per-game goal differential from the *team's* perspective.\n",
    "# # For shootouts: most NCAA datasets store regulation+OT goals only (SO adds no goals),\n",
    "# # so this calculation should already be correct. If your table encodes SO winner goals,\n",
    "# # strip those first.\n",
    "# long[\"gd\"] = (long[\"team_score\"].astype(int) - long[\"opp_score\"].astype(int))\n",
    "\n",
    "# # Cumulative all-time GD: this is the Y-value for a GD curve (step-like, changes only on game days)\n",
    "# long[\"cum_gd\"] = long.groupby(\"team_id\")[\"gd\"].cumsum()\n",
    "\n",
    "\n",
    "# timeline = long[[\n",
    "#     \"team_id\",\"team\",\"Date\",\"Game_ID\",\"Season_Year\",\"gp\",\n",
    "#     \"team_score\",\"opp_score\",          # (optional but handy)\n",
    "#     \"result\",\"delta\",                  # win/loss increment (for .500 curve)\n",
    "#     \"gd\",\"cum_gd\",                     # <-- NEW: per-game and cumulative GD\n",
    "#     \"cum_w\",\"cum_l\",\"cum_t\",\"games_above_500\",\n",
    "#     \"venue\"\n",
    "# ]].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a6b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def summarize_team(g: pd.DataFrame) -> pd.Series:\n",
    "#     g = g.sort_values(\"Date\")\n",
    "#     at500 = g[g[\"games_above_500\"] == 0]\n",
    "\n",
    "#     # Locate max/min cumulative GD rows\n",
    "#     max_gd_idx = g[\"cum_gd\"].idxmax()\n",
    "#     min_gd_idx = g[\"cum_gd\"].idxmin()\n",
    "\n",
    "#     return pd.Series({\n",
    "#         \"team\": g[\"team\"].iloc[0],\n",
    "#         \"first_date\": g[\"Date\"].min(),\n",
    "#         \"last_date\":  g[\"Date\"].max(),\n",
    "\n",
    "#         # .500 curve milestones (you already had these)\n",
    "#         \"max_point\":  g[\"games_above_500\"].max(),\n",
    "#         \"max_date\":   g.loc[g[\"games_above_500\"].idxmax(),\"Date\"],\n",
    "#         \"min_point\":  g[\"games_above_500\"].min(),\n",
    "#         \"min_date\":   g.loc[g[\"games_above_500\"].idxmin(),\"Date\"],\n",
    "#         \"final_w\":    g[\"cum_w\"].iloc[-1],\n",
    "#         \"final_l\":    g[\"cum_l\"].iloc[-1],\n",
    "#         \"final_t\":    g[\"cum_t\"].iloc[-1],\n",
    "#         \"final_games_above_500\": g[\"games_above_500\"].iloc[-1],\n",
    "#         \"last_500_date\": at500[\"Date\"].iloc[-1] if not at500.empty else pd.NaT,\n",
    "\n",
    "#         # --- NEW: GD milestones\n",
    "#         \"max_cum_gd\": g.loc[max_gd_idx, \"cum_gd\"],\n",
    "#         \"max_cum_gd_date\": g.loc[max_gd_idx, \"Date\"],\n",
    "#         \"min_cum_gd\": g.loc[min_gd_idx, \"cum_gd\"],\n",
    "#         \"min_cum_gd_date\": g.loc[min_gd_idx, \"Date\"],\n",
    "#         \"final_cum_gd\": g[\"cum_gd\"].iloc[-1],\n",
    "#     })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603cfaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_team_goal_diff_styled(timeline, team_name_or_id,\n",
    "                               era_marks=(1970, 1980, 1990, 2000, 2010, 2020, 2030),\n",
    "                               line_color=\"#E6A000\",       # warm golden line\n",
    "                               fill_above=\"#FFD98F\",       # light gold\n",
    "                               fill_below=\"#FFD98F\",       # same fill; tweak if you want 2-tone\n",
    "                               figsize=(16,6)):\n",
    "    \"\"\"\n",
    "    Draw a 'cumulative goal differential' chart styled like the .500 graphic.\n",
    "    Requires timeline to include: Date, cum_gd, cum_w, cum_l, cum_t.\n",
    "\n",
    "    Example:\n",
    "        tl = pd.read_csv(\"team_timeseries.csv\", parse_dates=[\"Date\"])\n",
    "        plot_team_goal_diff_styled(tl, \"Michigan State\")\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    if \"cum_gd\" not in timeline.columns:\n",
    "        raise ValueError(\"cum_gd missing from timeline. Re-run transform with GD patches.\")\n",
    "\n",
    "    # Select team\n",
    "    if isinstance(team_name_or_id, (int, np.integer)):\n",
    "        g = timeline[timeline[\"team_id\"] == team_name_or_id].copy()\n",
    "        label = str(team_name_or_id)\n",
    "    else:\n",
    "        g = timeline[timeline[\"team\"].str.casefold() == str(team_name_or_id).casefold()].copy()\n",
    "        label = str(team_name_or_id)\n",
    "\n",
    "    if g.empty:\n",
    "        raise ValueError(f\"No rows for team '{team_name_or_id}'\")\n",
    "\n",
    "    g = g.sort_values(\"Date\").reset_index(drop=True)\n",
    "    x = g[\"Date\"].values\n",
    "    y = g[\"cum_gd\"].astype(float).values\n",
    "\n",
    "    # Milestones\n",
    "    max_idx = int(np.nanargmax(y))\n",
    "    min_idx = int(np.nanargmin(y))\n",
    "    last_zero = g.loc[g[\"cum_gd\"] == 0, \"Date\"].max()  # most recent date at zero GD (if any)\n",
    "\n",
    "    # Final record & GD\n",
    "    final_w = int(g[\"cum_w\"].iloc[-1]); final_l = int(g[\"cum_l\"].iloc[-1]); final_t = int(g[\"cum_t\"].iloc[-1])\n",
    "    final_gd = int(g[\"cum_gd\"].iloc[-1])\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.step(x, y, where=\"post\", lw=2.2, color=line_color)\n",
    "    ax.fill_between(x, 0, y, where=y>0, step=\"post\", alpha=0.28, color=fill_above)\n",
    "    ax.fill_between(x, 0, y, where=y<0, step=\"post\", alpha=0.18, color=fill_below)\n",
    "    ax.axhline(0, lw=1.2, color=\"0.25\")\n",
    "\n",
    "    # Era/decade markers\n",
    "    for yr in era_marks:\n",
    "        ax.axvline(pd.Timestamp(f\"{yr}-01-01\"), ls=\"--\", lw=0.8, color=\"0.65\")\n",
    "\n",
    "    # Annotations: highest/lowest & last-zero-GD\n",
    "    ax.plot(g[\"Date\"].iloc[max_idx], y[max_idx], \"o\", ms=5, color=line_color)\n",
    "    ax.annotate(f\"Highest GD: {int(y[max_idx])}\\n{pd.to_datetime(x[max_idx]).date()}\",\n",
    "                (g[\"Date\"].iloc[max_idx], y[max_idx]), xytext=(10, 10),\n",
    "                textcoords=\"offset points\")\n",
    "\n",
    "    ax.plot(g[\"Date\"].iloc[min_idx], y[min_idx], \"o\", ms=5, color=line_color)\n",
    "    ax.annotate(f\"Lowest GD: {int(y[min_idx])}\\n{pd.to_datetime(x[min_idx]).date()}\",\n",
    "                (g[\"Date\"].iloc[min_idx], y[min_idx]), xytext=(10, -22),\n",
    "                textcoords=\"offset points\")\n",
    "\n",
    "    if pd.notna(last_zero):\n",
    "        last_val = float(g.loc[g[\"Date\"] == last_zero, \"cum_gd\"].iloc[-1])\n",
    "        ax.plot(last_zero, last_val, \"o\", ms=5, color=\"tab:purple\")\n",
    "        ax.annotate(f\"Last 0 GD: {last_zero.date()}\",\n",
    "                    (last_zero, last_val), xytext=(10, 10),\n",
    "                    textcoords=\"offset points\")\n",
    "\n",
    "    # Title & labels\n",
    "    title = g[\"team\"].iloc[0]\n",
    "    ax.set_title(f\"{title}: Cumulative Goal Differential Over Time\", pad=10)\n",
    "    ax.set_ylabel(\"Cumulative Goal Differential\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.margins(x=0.01)\n",
    "\n",
    "    # Footer badge\n",
    "    footer = f\"Final Record: {final_w}-{final_l}-{final_t}   Final GD: {final_gd:+d}\"\n",
    "    fig.text(0.99, 0.02, footer, ha=\"right\", va=\"bottom\",\n",
    "             bbox=dict(boxstyle=\"round,pad=0.35\", fc=\"#FFE7B8\", ec=line_color, lw=1.2))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcecbd60",
   "metadata": {},
   "source": [
    "### Call Goal Differential Plot\n",
    "- set tl = to team_summary table\n",
    "- pass tl and Team name string to plot_team_goal_diff_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2297a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = pd.read_csv(\"../data/tables/team_summary.csv\", parse_dates=[\"Date\"])\n",
    "\n",
    "if \"cum_gd\" not in tl.columns:\n",
    "    if {\"team_score\", \"opp_score\"}.issubset(tl.columns):\n",
    "        tl[\"gd\"] = tl[\"team_score\"].astype(\"int64\") - tl[\"opp_score\"].astype(\"int64\")\n",
    "        tl[\"cum_gd\"] = tl.groupby(\"team_id\")[\"gd\"].cumsum()\n",
    "        tl.to_csv(TIMELINE_CSV, index=False)\n",
    "        print(\"Patched timeline with gd/cum_gd and saved.\")\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Timeline missing cum_gd and also lacks team_score/opp_score. \"\n",
    "            \"Re-run the transform so those columns are included.\"\n",
    "        )\n",
    "else:\n",
    "    print(\"Timeline already has cum_gd.\")\n",
    "#  Use the timeseries, not the summary\n",
    "# tl = pd.read_csv(\"../TEMP/team_timeseries.csv\", parse_dates=[\"Date\"])\n",
    "\n",
    "# sanity check\n",
    "# assert \"cum_gd\" in tl.columns and \"Date\" in tl.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfcf09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot\n",
    "plot_team_goal_diff_styled(tl, \"Michigan State\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
