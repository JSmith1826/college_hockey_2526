{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7f26109",
   "metadata": {},
   "source": [
    "# Create Dataset of Head Coach and Home Arena data for all D1 Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de4ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating table for each team from CHN Team History Tab\n",
    "\n",
    "# Base URL Example\n",
    "# https://www.collegehockeynews.com/reports/teamHistory/Air-Force/1\n",
    "\n",
    "# page with table of season, w-l-t record - coach  and home arena - should also be able to infer conference membership info from the table\n",
    "# use these pages to make a time series of coach tenures and arena occupancy for all teams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cc16d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe60771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "BASE_URL = \"https://www.collegehockeynews.com/reports/teamHistory/\"\n",
    "\n",
    "# --- text normalization helpers ---------------------------------------------\n",
    "\n",
    "_HYPHEN_MAP = str.maketrans({\n",
    "    \"\\u2010\": \"-\", \"\\u2011\": \"-\", \"\\u2012\": \"-\", \"\\u2013\": \"-\", \"\\u2014\": \"-\", \"\\u2212\": \"-\",\n",
    "})\n",
    "\n",
    "def _fix_mojibake(s: str) -> str:\n",
    "    if s is None: return None\n",
    "    s = str(s)\n",
    "    try:\n",
    "        s2 = s.encode(\"latin1\").decode(\"utf-8\")\n",
    "        if s.count(\"â\") >= s2.count(\"â\"):\n",
    "            s = s2\n",
    "    except Exception:\n",
    "        pass\n",
    "    s = s.replace(\"Â\", \"\").replace(\"\\xa0\", \" \")\n",
    "    s = s.translate(_HYPHEN_MAP)\n",
    "    s = re.sub(r\"\\s*-\\s*\", \"-\", s)\n",
    "    s = re.sub(r\"[ \\t]+\", \" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "def _norm_season(s: str) -> str:\n",
    "    return _fix_mojibake(s)\n",
    "\n",
    "def _slugify_team(name: str) -> str:\n",
    "    s = name.strip().replace(\"&\", \"and\")\n",
    "    s = re.sub(r\"[’'`]\", \"\", s)\n",
    "    s = re.sub(r\"[.]\", \"\", s)\n",
    "    s = re.sub(r\"[^A-Za-z0-9]+\", \"-\", s)\n",
    "    return re.sub(r\"-{2,}\", \"-\", s).strip(\"-\")\n",
    "\n",
    "# --- nickname stripping ------------------------------------------------------\n",
    "\n",
    "_MULTI_NICK = {\n",
    "    \"River Hawks\",\"Golden Gophers\",\"Fighting Irish\",\"Fighting Hawks\",\n",
    "    \"Purple Eagles\",\"Black Bears\",\"Golden Knights\",\"Big Green\",\"Big Red\",\n",
    "    \"Red Hawks\",\"RedHawks\",\"Garnet Chargers\",\n",
    "}\n",
    "_SINGLE_NICK = {\n",
    "    \"Falcons\",\"Spartans\",\"Lakers\",\"Wildcats\",\"Huskies\",\"Pioneers\",\"Tigers\",\n",
    "    \"Bobcats\",\"Catamounts\",\"Eagles\",\"Warriors\",\"Minutemen\",\"Mavericks\",\n",
    "    \"Broncos\",\"Friars\",\"Seawolves\",\"Nanooks\",\"Beavers\",\"Tommies\",\"Bulldogs\",\n",
    "    \"Dutchmen\",\"Engineers\",\"Saints\",\"Crimson\",\"Raiders\",\"Terriers\",\"Gophers\",\n",
    "    \"Sharks\",\"Lions\",\"Skyhawks\",\"Vikings\",\"Fighting\",\"Irish\",\"Hawks\",\n",
    "}\n",
    "\n",
    "# school-name fixes to align with your other tables\n",
    "_SCHOOL_OVERRIDES = {\n",
    "    # Hockey East / Boston schools\n",
    "    \"Boston College\": \"Boston College\",\n",
    "    \"Boston University\": \"Boston University\",\n",
    "    \"Massachusetts\": \"Massachusetts\",        # UMass\n",
    "    \"UMass\": \"Massachusetts\",\n",
    "    \"UMass Lowell\": \"Mass Lowell\",\n",
    "    \"Massachusetts Lowell\": \"Mass Lowell\",\n",
    "    \"UConn\": \"Connecticut\",\n",
    "    \"Connecticut\": \"Connecticut\",\n",
    "    \"Merrimack\": \"Merrimack\",\n",
    "    \"Northeastern\": \"Northeastern\",\n",
    "    \"Providence\": \"Providence\",\n",
    "    \"Vermont\": \"Vermont\",\n",
    "    \"New Hampshire\": \"New Hampshire\",\n",
    "    \"Maine\": \"Maine\",\n",
    "\n",
    "    # B1G\n",
    "    \"Michigan\": \"Michigan\",\n",
    "    \"Michigan State\": \"Michigan State\",\n",
    "    \"Minnesota\": \"Minnesota\",\n",
    "    \"Notre Dame\": \"Notre Dame\",\n",
    "    \"Ohio State\": \"Ohio State\",\n",
    "    \"Penn State\": \"Penn State\",\n",
    "    \"Wisconsin\": \"Wisconsin\",\n",
    "\n",
    "    # CCHA\n",
    "    \"Augustana\": \"Augustana\",\n",
    "    \"Bemidji State\": \"Bemidji State\",\n",
    "    \"Bowling Green\": \"Bowling Green\",\n",
    "    \"Ferris State\": \"Ferris State\",\n",
    "    \"Lake Superior State\": \"Lake Superior\",\n",
    "    \"Lake Superior\": \"Lake Superior\",\n",
    "    \"Michigan Tech\": \"Michigan Tech\",\n",
    "    \"Minnesota State\": \"Minnesota State\",\n",
    "    \"Northern Michigan\": \"Northern Michigan\",\n",
    "    \"St Thomas\": \"St Thomas\",\n",
    "\n",
    "    # ECAC\n",
    "    \"Brown\": \"Brown\",\n",
    "    \"Clarkson\": \"Clarkson\",\n",
    "    \"Colgate\": \"Colgate\",\n",
    "    \"Cornell\": \"Cornell\",\n",
    "    \"Dartmouth\": \"Dartmouth\",\n",
    "    \"Harvard\": \"Harvard\",\n",
    "    \"Princeton\": \"Princeton\",\n",
    "    \"Quinnipiac\": \"Quinnipiac\",\n",
    "    \"Rensselaer\": \"Rensselaer\",\n",
    "    \"RPI\": \"Rensselaer\",\n",
    "    \"St Lawrence\": \"St Lawrence\",\n",
    "    \"St. Lawrence\": \"St Lawrence\",\n",
    "    \"Union\": \"Union\",\n",
    "    \"Yale\": \"Yale\",\n",
    "\n",
    "    # NCHC\n",
    "    \"Arizona State\": \"Arizona State\",\n",
    "    \"Colorado College\": \"Colorado College\",\n",
    "    \"Denver\": \"Denver\",\n",
    "    \"Miami\": \"Miami\",\n",
    "    \"Minnesota Duluth\": \"Minnesota Duluth\",\n",
    "    \"North Dakota\": \"North Dakota\",\n",
    "    \"Omaha\": \"Omaha\",\n",
    "    \"St Cloud State\": \"St Cloud State\",\n",
    "    \"St. Cloud State\": \"St Cloud State\",\n",
    "    \"Western Michigan\": \"Western Michigan\",\n",
    "\n",
    "    # Atlantic + Independents\n",
    "    \"Air Force\": \"Air Force\",\n",
    "    \"Army\": \"Army\",\n",
    "    \"American International\": \"American Intl\",\n",
    "    \"American International College\": \"American Intl\",\n",
    "    \"American Intl\": \"American Intl\",\n",
    "    \"AIC\": \"American Intl\",\n",
    "    \"Bentley\": \"Bentley\",\n",
    "    \"Canisius\": \"Canisius\",\n",
    "    \"Holy Cross\": \"Holy Cross\",\n",
    "    \"Mercyhurst\": \"Mercyhurst\",\n",
    "    \"Niagara\": \"Niagara\",\n",
    "    \"RIT\": \"RIT\",\n",
    "    \"Robert Morris\": \"Robert Morris\",\n",
    "    \"Sacred Heart\": \"Sacred Heart\",\n",
    "\n",
    "    # Independents\n",
    "    \"Alaska Anchorage\": \"Alaska Anchorage\",\n",
    "    \"Alaska\": \"Alaska\",\n",
    "    \"Lindenwood\": \"Lindenwood\",\n",
    "    \"Long Island\": \"Long Island\",\n",
    "    \"Stonehill\": \"Stonehill\",\n",
    "}\n",
    "\n",
    "def _strip_nickname(team_full: str) -> str:\n",
    "    \"\"\"Return school name w/o nickname; apply overrides and Saint/Mass variants.\"\"\"\n",
    "    if not team_full:\n",
    "        return team_full\n",
    "    t = _fix_mojibake(team_full)\n",
    "\n",
    "    # Normalize Saint & Mass variants for matching\n",
    "    t = re.sub(r\"\\bSt\\.\\b\", \"St\", t)\n",
    "    t = re.sub(r\"\\bMassachusetts\\-Lowell\\b\", \"UMass Lowell\", t)\n",
    "\n",
    "    # If the leading part already matches an override key, use it\n",
    "    for key in sorted(_SCHOOL_OVERRIDES.keys(), key=len, reverse=True):\n",
    "        if t.startswith(key):\n",
    "            return _SCHOOL_OVERRIDES[key]\n",
    "\n",
    "    # Otherwise, drop a trailing nickname\n",
    "    words = t.split()\n",
    "    # try multi-word endings first\n",
    "    for nick in sorted(_MULTI_NICK, key=len, reverse=True):\n",
    "        nick_words = nick.split()\n",
    "        if [w.lower() for w in words[-len(nick_words):]] == [w.lower() for w in nick_words]:\n",
    "            core = \" \".join(words[:-len(nick_words)])\n",
    "            core = core.strip()\n",
    "            # final pass through overrides to map forms like 'UMass Lowell' -> 'Mass Lowell'\n",
    "            return _SCHOOL_OVERRIDES.get(core, core)\n",
    "\n",
    "    # then single word nickname\n",
    "    if words and words[-1] in _SINGLE_NICK:\n",
    "        core = \" \".join(words[:-1]).strip()\n",
    "        return _SCHOOL_OVERRIDES.get(core, core)\n",
    "\n",
    "    # fallback: return as-is (then normalize via overrides if match)\n",
    "    return _SCHOOL_OVERRIDES.get(t, t)\n",
    "\n",
    "# --- header parsing & table choice ------------------------------------------\n",
    "\n",
    "def _parse_header_line(header_text: str):\n",
    "    team_full = header_text.split(\"|\", 1)[0].strip()\n",
    "    m = re.search(r\"\\(([^)]+)\\)\", header_text)\n",
    "    conf = m.group(1).strip() if m else None\n",
    "    school = _strip_nickname(team_full)\n",
    "    return school, _fix_mojibake(conf) if conf else None\n",
    "\n",
    "def _pick_history_table(tables):\n",
    "    for t in tables:\n",
    "        cols = [str(c).strip() for c in t.columns]\n",
    "        if \"Season\" in cols and \"Coach\" in cols and any(c == \"Home Arena\" for c in cols):\n",
    "            return t\n",
    "    return tables[0] if tables else None\n",
    "\n",
    "# --- table cleaner -----------------------------------------------------------\n",
    "\n",
    "def _clean_single_history_table(raw_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    wanted = [\"Season\", \"W\", \"L\", \"T\", \"Coach\", \"Home Arena\", \"RS\", \"CT\", \"NCAAs\"]\n",
    "    keep = []\n",
    "    for want in wanted:\n",
    "        match = next((c for c in raw_df.columns if str(c).strip() == want), None)\n",
    "        if match is not None:\n",
    "            keep.append(match)\n",
    "    df = raw_df[keep].copy()\n",
    "    for col in [\"Coach\",\"Home Arena\",\"RS\",\"CT\",\"NCAAs\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = pd.NA\n",
    "\n",
    "    rows = []\n",
    "    current_team, current_conf = None, None\n",
    "\n",
    "    for _, r in df.iterrows():\n",
    "        season_raw = r.iloc[0]\n",
    "        season_txt = _norm_season(season_raw)\n",
    "\n",
    "        if \"Division:\" in season_txt and \"|\" in season_txt:\n",
    "            current_team, current_conf = _parse_header_line(season_txt)\n",
    "            continue\n",
    "\n",
    "        if not re.match(r\"^\\d{4}\", season_txt):\n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"Team\": current_team,  # <-- school name now (no nickname)\n",
    "            \"Season\": season_txt,\n",
    "            \"W\": pd.to_numeric(r.get(\"W\"), errors=\"coerce\"),\n",
    "            \"L\": pd.to_numeric(r.get(\"L\"), errors=\"coerce\"),\n",
    "            \"T\": pd.to_numeric(r.get(\"T\"), errors=\"coerce\"),\n",
    "            \"Coach\": _fix_mojibake(r.get(\"Coach\")) if pd.notna(r.get(\"Coach\")) else None,\n",
    "            \"Home Arena\": _fix_mojibake(r.get(\"Home Arena\")) if pd.notna(r.get(\"Home Arena\")) else None,\n",
    "            \"Conference\": current_conf,\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(rows, columns=[\n",
    "        \"Team\",\"Season\",\"W\",\"L\",\"T\",\"Coach\",\"Home Arena\",\"Conference\"\n",
    "    ])\n",
    "\n",
    "    for col in [\"W\",\"L\",\"T\"]:\n",
    "        out[col] = out[col].astype(\"Int64\")\n",
    "    out[\"SeasonYear\"] = out[\"Season\"].str.extract(r\"^(\\d{4})\").astype(\"Int64\")\n",
    "    return out\n",
    "\n",
    "# --- main entrypoint ---------------------------------------------------------\n",
    "\n",
    "def scrape_chn_histories(team_names,\n",
    "                         base_url: str = BASE_URL,\n",
    "                         slug_overrides: dict | None = None,\n",
    "                         progress: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns columns:\n",
    "      Team (school only), Season, W, L, T, Coach, Home Arena, Conference, SeasonYear\n",
    "    \"\"\"\n",
    "    slug_overrides = slug_overrides or {}\n",
    "    frames = []\n",
    "\n",
    "    for team in team_names:\n",
    "        slug = slug_overrides.get(team, _slugify_team(team))\n",
    "        url = base_url.rstrip(\"/\") + \"/\" + slug\n",
    "        if progress:\n",
    "            print(f\"Fetching {team} -> {url}\")\n",
    "\n",
    "        try:\n",
    "            tables = pd.read_html(url, header=0)\n",
    "        except Exception as e:\n",
    "            if progress: print(f\"  ! Failed for {team}: {e}\")\n",
    "            continue\n",
    "\n",
    "        tbl = _pick_history_table(tables)\n",
    "        if tbl is None:\n",
    "            if progress: print(f\"  ! No history table for {team}\")\n",
    "            continue\n",
    "\n",
    "        cleaned = _clean_single_history_table(tbl)\n",
    "        if cleaned.get(\"Team\").isna().all():\n",
    "            # If we somehow missed the header, strip nickname from the input\n",
    "            cleaned[\"Team\"] = _strip_nickname(team)\n",
    "\n",
    "        # final polish on strings\n",
    "        for col in [\"Team\",\"Season\",\"Coach\",\"Home Arena\",\"Conference\"]:\n",
    "            cleaned[col] = cleaned[col].map(_fix_mojibake)\n",
    "\n",
    "        frames.append(cleaned)\n",
    "\n",
    "    if not frames:\n",
    "        return pd.DataFrame(columns=[\"Team\",\"Season\",\"W\",\"L\",\"T\",\"Coach\",\"Home Arena\",\"Conference\",\"SeasonYear\"])\n",
    "\n",
    "    df = pd.concat(frames, ignore_index=True)\n",
    "    df = df.sort_values([\"Team\",\"SeasonYear\"], ascending=[True, False])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4682e665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Air Force',\n",
       " 'Alaska',\n",
       " 'Alaska Anchorage',\n",
       " \"American Int'l\",\n",
       " 'Arizona State',\n",
       " 'Army',\n",
       " 'Bemidji State',\n",
       " 'Bentley',\n",
       " 'Boston College',\n",
       " 'Boston University',\n",
       " 'Bowling Green',\n",
       " 'Brown',\n",
       " 'Canisius',\n",
       " 'Clarkson',\n",
       " 'Colgate',\n",
       " 'Colorado College',\n",
       " 'Connecticut',\n",
       " 'Cornell',\n",
       " 'Dartmouth',\n",
       " 'Denver',\n",
       " 'Ferris State',\n",
       " 'Harvard',\n",
       " 'Holy Cross',\n",
       " 'Lake Superior',\n",
       " 'Long Island',\n",
       " 'Mass Lowell',\n",
       " 'Massachusetts',\n",
       " 'Mercyhurst',\n",
       " 'Merrimack',\n",
       " 'Miami',\n",
       " 'Michigan',\n",
       " 'Michigan State',\n",
       " 'Michigan Tech',\n",
       " 'Minnesota',\n",
       " 'Minnesota State',\n",
       " 'Minnesota Duluth',\n",
       " 'New Hampshire',\n",
       " 'Niagara',\n",
       " 'North Dakota',\n",
       " 'Northeastern',\n",
       " 'Northern Michigan',\n",
       " 'Notre Dame',\n",
       " 'Ohio State',\n",
       " 'Penn State',\n",
       " 'Princeton',\n",
       " 'Providence',\n",
       " 'Quinnipiac',\n",
       " 'Rensselaer',\n",
       " 'RIT',\n",
       " 'Robert Morris',\n",
       " 'Sacred Heart',\n",
       " 'St. Cloud State',\n",
       " 'St Lawrence',\n",
       " 'St Thomas',\n",
       " 'Union',\n",
       " 'Vermont',\n",
       " 'Western Michigan',\n",
       " 'Wisconsin',\n",
       " 'Yale',\n",
       " 'Stonehill',\n",
       " 'Lindenwood',\n",
       " 'Augustana',\n",
       " 'Omaha',\n",
       " 'Maine',\n",
       " 'Mass. Lowell',\n",
       " 'American Intl',\n",
       " 'St Cloud State',\n",
       " 'St. Lawrence',\n",
       " 'St. Thomas']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load school info table to make list of all team names\n",
    "\n",
    "school_info_path = '../data/school_info/arena_school_info.csv'\n",
    "# Read the table\n",
    "school_info_df = pd.read_csv(school_info_path)\n",
    "school_info_df.head()\n",
    "\n",
    "# create a list from the Team Column\n",
    "teams = school_info_df['Team'].tolist()\n",
    "teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf1ad63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Air Force -> https://www.collegehockeynews.com/reports/teamHistory/Air-Force\n",
      "Fetching Alaska -> https://www.collegehockeynews.com/reports/teamHistory/Alaska\n",
      "Fetching Alaska Anchorage -> https://www.collegehockeynews.com/reports/teamHistory/Alaska-Anchorage\n",
      "Fetching American Int'l -> https://www.collegehockeynews.com/reports/teamHistory/American-Intl\n",
      "Fetching Arizona State -> https://www.collegehockeynews.com/reports/teamHistory/Arizona-State\n",
      "Fetching Army -> https://www.collegehockeynews.com/reports/teamHistory/Army\n",
      "Fetching Bemidji State -> https://www.collegehockeynews.com/reports/teamHistory/Bemidji-State\n",
      "Fetching Bentley -> https://www.collegehockeynews.com/reports/teamHistory/Bentley\n",
      "Fetching Boston College -> https://www.collegehockeynews.com/reports/teamHistory/Boston-College\n",
      "Fetching Boston University -> https://www.collegehockeynews.com/reports/teamHistory/Boston-University\n",
      "Fetching Bowling Green -> https://www.collegehockeynews.com/reports/teamHistory/Bowling-Green\n",
      "Fetching Brown -> https://www.collegehockeynews.com/reports/teamHistory/Brown\n",
      "Fetching Canisius -> https://www.collegehockeynews.com/reports/teamHistory/Canisius\n",
      "Fetching Clarkson -> https://www.collegehockeynews.com/reports/teamHistory/Clarkson\n",
      "Fetching Colgate -> https://www.collegehockeynews.com/reports/teamHistory/Colgate\n",
      "Fetching Colorado College -> https://www.collegehockeynews.com/reports/teamHistory/Colorado-College\n",
      "Fetching Connecticut -> https://www.collegehockeynews.com/reports/teamHistory/Connecticut\n",
      "Fetching Cornell -> https://www.collegehockeynews.com/reports/teamHistory/Cornell\n",
      "Fetching Dartmouth -> https://www.collegehockeynews.com/reports/teamHistory/Dartmouth\n",
      "Fetching Denver -> https://www.collegehockeynews.com/reports/teamHistory/Denver\n",
      "Fetching Ferris State -> https://www.collegehockeynews.com/reports/teamHistory/Ferris-State\n",
      "Fetching Harvard -> https://www.collegehockeynews.com/reports/teamHistory/Harvard\n",
      "Fetching Holy Cross -> https://www.collegehockeynews.com/reports/teamHistory/Holy-Cross\n",
      "Fetching Lake Superior -> https://www.collegehockeynews.com/reports/teamHistory/Lake-Superior\n",
      "Fetching Long Island -> https://www.collegehockeynews.com/reports/teamHistory/Long-Island\n",
      "Fetching Mass Lowell -> https://www.collegehockeynews.com/reports/teamHistory/Mass-Lowell\n",
      "Fetching Massachusetts -> https://www.collegehockeynews.com/reports/teamHistory/Massachusetts\n",
      "Fetching Mercyhurst -> https://www.collegehockeynews.com/reports/teamHistory/Mercyhurst\n",
      "Fetching Merrimack -> https://www.collegehockeynews.com/reports/teamHistory/Merrimack\n",
      "Fetching Miami -> https://www.collegehockeynews.com/reports/teamHistory/Miami\n",
      "Fetching Michigan -> https://www.collegehockeynews.com/reports/teamHistory/Michigan\n",
      "Fetching Michigan State -> https://www.collegehockeynews.com/reports/teamHistory/Michigan-State\n",
      "Fetching Michigan Tech -> https://www.collegehockeynews.com/reports/teamHistory/Michigan-Tech\n",
      "Fetching Minnesota -> https://www.collegehockeynews.com/reports/teamHistory/Minnesota\n",
      "Fetching Minnesota State -> https://www.collegehockeynews.com/reports/teamHistory/Minnesota-State\n",
      "Fetching Minnesota Duluth -> https://www.collegehockeynews.com/reports/teamHistory/Minnesota-Duluth\n",
      "Fetching New Hampshire -> https://www.collegehockeynews.com/reports/teamHistory/New-Hampshire\n",
      "Fetching Niagara -> https://www.collegehockeynews.com/reports/teamHistory/Niagara\n",
      "Fetching North Dakota -> https://www.collegehockeynews.com/reports/teamHistory/North-Dakota\n",
      "Fetching Northeastern -> https://www.collegehockeynews.com/reports/teamHistory/Northeastern\n",
      "Fetching Northern Michigan -> https://www.collegehockeynews.com/reports/teamHistory/Northern-Michigan\n",
      "Fetching Notre Dame -> https://www.collegehockeynews.com/reports/teamHistory/Notre-Dame\n",
      "Fetching Ohio State -> https://www.collegehockeynews.com/reports/teamHistory/Ohio-State\n",
      "Fetching Penn State -> https://www.collegehockeynews.com/reports/teamHistory/Penn-State\n",
      "Fetching Princeton -> https://www.collegehockeynews.com/reports/teamHistory/Princeton\n",
      "Fetching Providence -> https://www.collegehockeynews.com/reports/teamHistory/Providence\n",
      "Fetching Quinnipiac -> https://www.collegehockeynews.com/reports/teamHistory/Quinnipiac\n",
      "Fetching Rensselaer -> https://www.collegehockeynews.com/reports/teamHistory/Rensselaer\n",
      "Fetching RIT -> https://www.collegehockeynews.com/reports/teamHistory/RIT\n",
      "Fetching Robert Morris -> https://www.collegehockeynews.com/reports/teamHistory/Robert-Morris\n",
      "Fetching Sacred Heart -> https://www.collegehockeynews.com/reports/teamHistory/Sacred-Heart\n",
      "Fetching St. Cloud State -> https://www.collegehockeynews.com/reports/teamHistory/St-Cloud-State\n",
      "Fetching St Lawrence -> https://www.collegehockeynews.com/reports/teamHistory/St-Lawrence\n",
      "Fetching St Thomas -> https://www.collegehockeynews.com/reports/teamHistory/St-Thomas\n",
      "Fetching Union -> https://www.collegehockeynews.com/reports/teamHistory/Union\n",
      "Fetching Vermont -> https://www.collegehockeynews.com/reports/teamHistory/Vermont\n",
      "Fetching Western Michigan -> https://www.collegehockeynews.com/reports/teamHistory/Western-Michigan\n",
      "Fetching Wisconsin -> https://www.collegehockeynews.com/reports/teamHistory/Wisconsin\n",
      "Fetching Yale -> https://www.collegehockeynews.com/reports/teamHistory/Yale\n",
      "Fetching Stonehill -> https://www.collegehockeynews.com/reports/teamHistory/Stonehill\n",
      "Fetching Lindenwood -> https://www.collegehockeynews.com/reports/teamHistory/Lindenwood\n",
      "Fetching Augustana -> https://www.collegehockeynews.com/reports/teamHistory/Augustana\n",
      "Fetching Omaha -> https://www.collegehockeynews.com/reports/teamHistory/Omaha\n",
      "Fetching Maine -> https://www.collegehockeynews.com/reports/teamHistory/Maine\n",
      "Fetching Mass. Lowell -> https://www.collegehockeynews.com/reports/teamHistory/Mass-Lowell\n",
      "Fetching American Intl -> https://www.collegehockeynews.com/reports/teamHistory/American-Intl\n",
      "Fetching St Cloud State -> https://www.collegehockeynews.com/reports/teamHistory/St-Cloud-State\n",
      "Fetching St. Lawrence -> https://www.collegehockeynews.com/reports/teamHistory/St-Lawrence\n",
      "Fetching St. Thomas -> https://www.collegehockeynews.com/reports/teamHistory/St-Thomas\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Team",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Season",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "W",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "L",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "T",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "Coach",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Home Arena",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Conference",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SeasonYear",
         "rawType": "Int64",
         "type": "integer"
        }
       ],
       "ref": "2adc1a2d-e176-4ce6-b828-e4351a36c215",
       "rows": [
        [
         "0",
         "Air Force",
         "2025-26",
         "0",
         "0",
         "0",
         "Frank Serratore",
         "Cadet Ice Arena",
         "Atlantic Hockey",
         "2025"
        ],
        [
         "1",
         "Air Force",
         "2024-25",
         "16",
         "21",
         "3",
         "Frank Serratore",
         "Cadet Ice Arena",
         "Atlantic Hockey",
         "2024"
        ],
        [
         "2",
         "Air Force",
         "2023-24",
         "18",
         "19",
         "1",
         "Frank Serratore",
         "Cadet Ice Arena",
         "Atlantic Hockey",
         "2023"
        ],
        [
         "3",
         "Air Force",
         "2022-23",
         "12",
         "22",
         "2",
         "Frank Serratore",
         "Cadet Ice Arena",
         "Atlantic Hockey",
         "2022"
        ],
        [
         "4",
         "Air Force",
         "2021-22",
         "16",
         "17",
         "3",
         "Frank Serratore",
         "Cadet Ice Arena",
         "Atlantic Hockey",
         "2021"
        ],
        [
         "5",
         "Air Force",
         "2020-21",
         "3",
         "10",
         "1",
         "Frank Serratore",
         "Cadet Ice Arena",
         "Atlantic Hockey",
         "2020"
        ],
        [
         "6",
         "Air Force",
         "2019-20",
         "12",
         "18",
         "6",
         "Frank Serratore",
         "Cadet Ice Arena",
         "Atlantic Hockey",
         "2019"
        ],
        [
         "7",
         "Air Force",
         "2018-19",
         "16",
         "15",
         "5",
         "Frank Serratore",
         "Cadet Ice Arena",
         "Atlantic Hockey",
         "2018"
        ],
        [
         "8",
         "Air Force",
         "2017-18",
         "23",
         "15",
         "5",
         "Frank Serratore",
         "Cadet Ice Arena",
         "Atlantic Hockey",
         "2017"
        ],
        [
         "9",
         "Air Force",
         "2016-17",
         "27",
         "10",
         "5",
         "Frank Serratore",
         "Cadet Ice Arena",
         "Atlantic Hockey",
         "2016"
        ],
        [
         "10",
         "Air Force",
         "2015-16",
         "20",
         "12",
         "5",
         "Frank Serratore",
         "Cadet Ice Arena",
         "Atlantic Hockey",
         "2015"
        ],
        [
         "11",
         "Air Force",
         "2014-15",
         "16",
         "21",
         "4",
         "Frank Serratore",
         "Cadet Ice Arena",
         "Atlantic Hockey",
         "2014"
        ],
        [
         "12",
         "Air Force",
         "2013-14",
         "21",
         "14",
         "4",
         "Frank Serratore",
         "Cadet Ice Arena",
         "Atlantic Hockey",
         "2013"
        ],
        [
         "13",
         "Air Force",
         "2012-13",
         "17",
         "13",
         "7",
         "Frank Serratore",
         "Cadet Ice Arena",
         "Atlantic Hockey",
         "2012"
        ],
        [
         "14",
         "Air Force",
         "2011-12",
         "21",
         "11",
         "7",
         "Frank Serratore",
         "Cadet Ice Arena",
         "Atlantic Hockey",
         "2011"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 15
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Season</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>T</th>\n",
       "      <th>Coach</th>\n",
       "      <th>Home Arena</th>\n",
       "      <th>Conference</th>\n",
       "      <th>SeasonYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>2025-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Frank Serratore</td>\n",
       "      <td>Cadet Ice Arena</td>\n",
       "      <td>Atlantic Hockey</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>2024-25</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>Frank Serratore</td>\n",
       "      <td>Cadet Ice Arena</td>\n",
       "      <td>Atlantic Hockey</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>Frank Serratore</td>\n",
       "      <td>Cadet Ice Arena</td>\n",
       "      <td>Atlantic Hockey</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>Frank Serratore</td>\n",
       "      <td>Cadet Ice Arena</td>\n",
       "      <td>Atlantic Hockey</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Frank Serratore</td>\n",
       "      <td>Cadet Ice Arena</td>\n",
       "      <td>Atlantic Hockey</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>2020-21</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Frank Serratore</td>\n",
       "      <td>Cadet Ice Arena</td>\n",
       "      <td>Atlantic Hockey</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>Frank Serratore</td>\n",
       "      <td>Cadet Ice Arena</td>\n",
       "      <td>Atlantic Hockey</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>2018-19</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>Frank Serratore</td>\n",
       "      <td>Cadet Ice Arena</td>\n",
       "      <td>Atlantic Hockey</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>2017-18</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>Frank Serratore</td>\n",
       "      <td>Cadet Ice Arena</td>\n",
       "      <td>Atlantic Hockey</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>Frank Serratore</td>\n",
       "      <td>Cadet Ice Arena</td>\n",
       "      <td>Atlantic Hockey</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>2015-16</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>Frank Serratore</td>\n",
       "      <td>Cadet Ice Arena</td>\n",
       "      <td>Atlantic Hockey</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>2014-15</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>Frank Serratore</td>\n",
       "      <td>Cadet Ice Arena</td>\n",
       "      <td>Atlantic Hockey</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>2013-14</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>Frank Serratore</td>\n",
       "      <td>Cadet Ice Arena</td>\n",
       "      <td>Atlantic Hockey</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>2012-13</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>Frank Serratore</td>\n",
       "      <td>Cadet Ice Arena</td>\n",
       "      <td>Atlantic Hockey</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>2011-12</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>Frank Serratore</td>\n",
       "      <td>Cadet Ice Arena</td>\n",
       "      <td>Atlantic Hockey</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Team   Season   W   L  T            Coach       Home Arena  \\\n",
       "0   Air Force  2025-26   0   0  0  Frank Serratore  Cadet Ice Arena   \n",
       "1   Air Force  2024-25  16  21  3  Frank Serratore  Cadet Ice Arena   \n",
       "2   Air Force  2023-24  18  19  1  Frank Serratore  Cadet Ice Arena   \n",
       "3   Air Force  2022-23  12  22  2  Frank Serratore  Cadet Ice Arena   \n",
       "4   Air Force  2021-22  16  17  3  Frank Serratore  Cadet Ice Arena   \n",
       "5   Air Force  2020-21   3  10  1  Frank Serratore  Cadet Ice Arena   \n",
       "6   Air Force  2019-20  12  18  6  Frank Serratore  Cadet Ice Arena   \n",
       "7   Air Force  2018-19  16  15  5  Frank Serratore  Cadet Ice Arena   \n",
       "8   Air Force  2017-18  23  15  5  Frank Serratore  Cadet Ice Arena   \n",
       "9   Air Force  2016-17  27  10  5  Frank Serratore  Cadet Ice Arena   \n",
       "10  Air Force  2015-16  20  12  5  Frank Serratore  Cadet Ice Arena   \n",
       "11  Air Force  2014-15  16  21  4  Frank Serratore  Cadet Ice Arena   \n",
       "12  Air Force  2013-14  21  14  4  Frank Serratore  Cadet Ice Arena   \n",
       "13  Air Force  2012-13  17  13  7  Frank Serratore  Cadet Ice Arena   \n",
       "14  Air Force  2011-12  21  11  7  Frank Serratore  Cadet Ice Arena   \n",
       "\n",
       "         Conference  SeasonYear  \n",
       "0   Atlantic Hockey        2025  \n",
       "1   Atlantic Hockey        2024  \n",
       "2   Atlantic Hockey        2023  \n",
       "3   Atlantic Hockey        2022  \n",
       "4   Atlantic Hockey        2021  \n",
       "5   Atlantic Hockey        2020  \n",
       "6   Atlantic Hockey        2019  \n",
       "7   Atlantic Hockey        2018  \n",
       "8   Atlantic Hockey        2017  \n",
       "9   Atlantic Hockey        2016  \n",
       "10  Atlantic Hockey        2015  \n",
       "11  Atlantic Hockey        2014  \n",
       "12  Atlantic Hockey        2013  \n",
       "13  Atlantic Hockey        2012  \n",
       "14  Atlantic Hockey        2011  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# teams = [\"Michigan State\", \"Mercyhurst\", \"Air Force\", \"Mass Lowell\", \"St. Lawrence\"]\n",
    "df = scrape_chn_histories(teams)\n",
    "df.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eace5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "df.to_csv(\"../data/school_info/chn_team_histories.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36dc284a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Team",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Season",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "W",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "L",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "T",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "Coach",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Home Arena",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Conference",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SeasonYear",
         "rawType": "Int64",
         "type": "integer"
        }
       ],
       "ref": "d2abf34b-f2da-41fb-81e8-e7dc8a67a0a7",
       "rows": [
        [
         "4270",
         "Yale",
         "1914-15",
         "9",
         "6",
         "0",
         "No Coach",
         null,
         "D-I Independent",
         "1914"
        ],
        [
         "4271",
         "Yale",
         "1913-14",
         "8",
         "6",
         "0",
         "No Coach",
         null,
         "D-I Independent",
         "1913"
        ],
        [
         "4272",
         "Yale",
         "1912-13",
         "3",
         "7",
         "1",
         "No Coach",
         null,
         "D-I Independent",
         "1912"
        ],
        [
         "4273",
         "Yale",
         "1911-12",
         "11",
         "7",
         "0",
         "No Coach",
         null,
         "Intercollegiate",
         "1911"
        ],
        [
         "4274",
         "Yale",
         "1910-11",
         "6",
         "10",
         "0",
         "No Coach",
         null,
         "Intercollegiate",
         "1910"
        ],
        [
         "4275",
         "Yale",
         "1909-10",
         "8",
         "7",
         "0",
         "No Coach",
         null,
         "Intercollegiate",
         "1909"
        ],
        [
         "4276",
         "Yale",
         "1908-09",
         "4",
         "8",
         "1",
         "No Coach",
         null,
         "Intercollegiate",
         "1908"
        ],
        [
         "4277",
         "Yale",
         "1907-08",
         "6",
         "3",
         "0",
         "No Coach",
         null,
         "Intercollegiate",
         "1907"
        ],
        [
         "4278",
         "Yale",
         "1906-07",
         "3",
         "6",
         "0",
         "No Coach",
         null,
         "Intercollegiate",
         "1906"
        ],
        [
         "4279",
         "Yale",
         "1905-06",
         "7",
         "3",
         "1",
         "No Coach",
         null,
         "Intercollegiate",
         "1905"
        ],
        [
         "4280",
         "Yale",
         "1904-05",
         "7",
         "5",
         "0",
         "No Coach",
         null,
         "Intercollegiate",
         "1904"
        ],
        [
         "4281",
         "Yale",
         "1903-04",
         "4",
         "4",
         "2",
         "No Coach",
         null,
         "Intercollegiate",
         "1903"
        ],
        [
         "4282",
         "Yale",
         "1902-03",
         "4",
         "12",
         "1",
         "No Coach",
         null,
         "Intercollegiate",
         "1902"
        ],
        [
         "4283",
         "Yale",
         "1901-02",
         "6",
         "0",
         "0",
         "No Coach",
         null,
         "Intercollegiate",
         "1901"
        ],
        [
         "4284",
         "Yale",
         "1900-01",
         "5",
         "7",
         "1",
         "No Coach",
         null,
         "Intercollegiate",
         "1900"
        ],
        [
         "4285",
         "Yale",
         "1899-00",
         "10",
         "5",
         "0",
         "No Coach",
         null,
         "Intercollegiate",
         "1899"
        ],
        [
         "4286",
         "Yale",
         "1898-99",
         "8",
         "6",
         "0",
         "No Coach",
         null,
         "D-I Independent",
         "1898"
        ],
        [
         "4287",
         "Yale",
         "1897-98",
         "4",
         "3",
         "2",
         "No Coach",
         null,
         "D-I Independent",
         "1897"
        ],
        [
         "4288",
         "Yale",
         "1896-97",
         "2",
         "6",
         "1",
         "No Coach",
         null,
         "D-I Independent",
         "1896"
        ],
        [
         "4289",
         "Yale",
         "1895-96",
         "2",
         "0",
         "0",
         "No Coach",
         null,
         "D-I Independent",
         "1895"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Season</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>T</th>\n",
       "      <th>Coach</th>\n",
       "      <th>Home Arena</th>\n",
       "      <th>Conference</th>\n",
       "      <th>SeasonYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1914-15</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>D-I Independent</td>\n",
       "      <td>1914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1913-14</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>D-I Independent</td>\n",
       "      <td>1913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1912-13</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>D-I Independent</td>\n",
       "      <td>1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1911-12</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>Intercollegiate</td>\n",
       "      <td>1911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1910-11</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>Intercollegiate</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1909-10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>Intercollegiate</td>\n",
       "      <td>1909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1908-09</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>Intercollegiate</td>\n",
       "      <td>1908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1907-08</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>Intercollegiate</td>\n",
       "      <td>1907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4278</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1906-07</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>Intercollegiate</td>\n",
       "      <td>1906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1905-06</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>Intercollegiate</td>\n",
       "      <td>1905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1904-05</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>Intercollegiate</td>\n",
       "      <td>1904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1903-04</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>Intercollegiate</td>\n",
       "      <td>1903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1902-03</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>Intercollegiate</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1901-02</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>Intercollegiate</td>\n",
       "      <td>1901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1900-01</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>Intercollegiate</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1899-00</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>Intercollegiate</td>\n",
       "      <td>1899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1898-99</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>D-I Independent</td>\n",
       "      <td>1898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1897-98</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>D-I Independent</td>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4288</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1896-97</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>D-I Independent</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4289</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1895-96</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Coach</td>\n",
       "      <td>None</td>\n",
       "      <td>D-I Independent</td>\n",
       "      <td>1895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team   Season   W   L  T     Coach Home Arena       Conference  \\\n",
       "4270  Yale  1914-15   9   6  0  No Coach       None  D-I Independent   \n",
       "4271  Yale  1913-14   8   6  0  No Coach       None  D-I Independent   \n",
       "4272  Yale  1912-13   3   7  1  No Coach       None  D-I Independent   \n",
       "4273  Yale  1911-12  11   7  0  No Coach       None  Intercollegiate   \n",
       "4274  Yale  1910-11   6  10  0  No Coach       None  Intercollegiate   \n",
       "4275  Yale  1909-10   8   7  0  No Coach       None  Intercollegiate   \n",
       "4276  Yale  1908-09   4   8  1  No Coach       None  Intercollegiate   \n",
       "4277  Yale  1907-08   6   3  0  No Coach       None  Intercollegiate   \n",
       "4278  Yale  1906-07   3   6  0  No Coach       None  Intercollegiate   \n",
       "4279  Yale  1905-06   7   3  1  No Coach       None  Intercollegiate   \n",
       "4280  Yale  1904-05   7   5  0  No Coach       None  Intercollegiate   \n",
       "4281  Yale  1903-04   4   4  2  No Coach       None  Intercollegiate   \n",
       "4282  Yale  1902-03   4  12  1  No Coach       None  Intercollegiate   \n",
       "4283  Yale  1901-02   6   0  0  No Coach       None  Intercollegiate   \n",
       "4284  Yale  1900-01   5   7  1  No Coach       None  Intercollegiate   \n",
       "4285  Yale  1899-00  10   5  0  No Coach       None  Intercollegiate   \n",
       "4286  Yale  1898-99   8   6  0  No Coach       None  D-I Independent   \n",
       "4287  Yale  1897-98   4   3  2  No Coach       None  D-I Independent   \n",
       "4288  Yale  1896-97   2   6  1  No Coach       None  D-I Independent   \n",
       "4289  Yale  1895-96   2   0  0  No Coach       None  D-I Independent   \n",
       "\n",
       "      SeasonYear  \n",
       "4270        1914  \n",
       "4271        1913  \n",
       "4272        1912  \n",
       "4273        1911  \n",
       "4274        1910  \n",
       "4275        1909  \n",
       "4276        1908  \n",
       "4277        1907  \n",
       "4278        1906  \n",
       "4279        1905  \n",
       "4280        1904  \n",
       "4281        1903  \n",
       "4282        1902  \n",
       "4283        1901  \n",
       "4284        1900  \n",
       "4285        1899  \n",
       "4286        1898  \n",
       "4287        1897  \n",
       "4288        1896  \n",
       "4289        1895  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "556efe94",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    break\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660e4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.collegehockeynews.com/reports/teamHistory/Michigan-State/32\"\n",
    "msu = scrape_chn_team_history(url)\n",
    "msu.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4195c5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1ac5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_url = 'https://www.collegehockeynews.com/reports/teamHistory/Mercyhurst'\n",
    "\n",
    "# open url\n",
    "response = requests.get(example_url)\n",
    "\n",
    "\n",
    "# try to read page with pandas\n",
    "dfs = pd.read_html(example_url)\n",
    "dfs\n",
    "\n",
    "# show the first dataframe from list\n",
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc5c4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520f3508",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7294bc",
   "metadata": {},
   "source": [
    "# Scrape and add most recent seasons to all time results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30bd9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "### Parse the current season schedule / results page\n",
    "\n",
    "def parse_current_season(url):\n",
    "        # Initialize variables\n",
    "    current_date = None\n",
    "    current_conference = None\n",
    "    game_notes = None\n",
    "\n",
    "    # Initialize an empty list to hold the data\n",
    "    data = []\n",
    "\n",
    "    # Parse the page with BeautifulSoup\n",
    "    # Get the page with requests\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # select the table or tables\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    rows = soup.find_all('tr')\n",
    "\n",
    "    # Loop through each row to find relevant information\n",
    "    for row in rows:\n",
    "        # Check for date row\n",
    "        if row.get('class') == ['stats-section']:\n",
    "            current_date = row.find('td').text.strip()\n",
    "        # Check for conference row\n",
    "        elif row.get('class') == ['sked-header']:\n",
    "            current_conference = row.find('td').text.strip()\n",
    "        # Check for game notes\n",
    "        elif len(row.find_all('td')) == 2:\n",
    "            game_notes = row.find_all('td')[1].text.strip()\n",
    "        # Process rows with game data\n",
    "        elif row.get('valign') == 'top':\n",
    "            cells = row.find_all('td')\n",
    "            if len(cells) >= 9:\n",
    "                home_team = cells[0].text.strip()\n",
    "                # Remove any hyphens from the team name\n",
    "                home_team = home_team.replace('-', ' ')\n",
    "                home_team_link = cells[0].find('a')['href'] if cells[0].find('a') else None\n",
    "                home_score = cells[1].text.strip()\n",
    "                away_team = cells[3].text.strip()\n",
    "                away_team_link = cells[3].find('a')['href'] if cells[3].find('a') else None\n",
    "                away_score = cells[4].text.strip()\n",
    "                ot = cells[5].text.strip()\n",
    "                box_link = cells[7].find('a')['href'] if cells[7].find('a') else None\n",
    "                metrics_link = cells[8].find('a')['href'] if cells[8].find('a') else None\n",
    "                # Capture Game Notes\n",
    "                game_notes_cell = cells[-1].find('small')\n",
    "                game_notes = game_notes_cell.text.strip() if game_notes_cell else None\n",
    "\n",
    "                # Append data to the list\n",
    "                data.append([current_date, current_conference, game_notes, home_team, home_team_link, home_score, away_team, away_team_link, away_score, ot, box_link, metrics_link])\n",
    "                game_notes = None  # Reset game notes for the next row\n",
    "    return data\n",
    "\n",
    "\n",
    "### Set The Target Year\n",
    "# current_year_url = \"https://www.collegehockeynews.com/schedules/?season=20242025\" # 2024-2025 season\n",
    "current_year_url = \"https://www.collegehockeynews.com/schedules/?season=20232024\" # 2023-2024 season\n",
    "## call the function\n",
    "data = parse_current_season(current_year_url)\n",
    "\n",
    "\n",
    "# Create a dataframe from the list\n",
    "\n",
    "columns = ['Date', 'Conference', 'Game_Notes', 'Home_Team', 'Home_Team_Link', 'Home_Score', 'Away_Team', 'Away_Team_Link', 'Away_Score', 'OT', 'Box_Link', 'Metrics_Link']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "            \n",
    "## Extract the day of the week from the date and save in new column\n",
    "df['Day'] = pd.to_datetime(df['Date']).dt.day_name()\n",
    "# remove day of the week from date\n",
    "# format data column as YYYY-MM-DD\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "### Create a new column for the game ID\n",
    "## Game ID will be a combination of the date and abbreviated team names\n",
    "\n",
    "# Loop to abbreviate the team names\n",
    "for row in df.itertuples():\n",
    "    home_team = row.Home_Team\n",
    "    away_team = row.Away_Team\n",
    "    home_team_abbr = home_team.split(' ')[-1]\n",
    "    away_team_abbr = away_team.split(' ')[-1]\n",
    "    # Remove any hyphens from the team name if there are any\n",
    "    home_team_abbr = home_team_abbr.replace('-', ' ')\n",
    "    away_team_abbr = away_team_abbr.replace('-', ' ')\n",
    "    game_id = f'{row.Date}-{home_team_abbr}-{away_team_abbr}'\n",
    "    df.loc[row.Index, 'Game_ID'] = game_id\n",
    "\n",
    "# Create a new column for the game ID\n",
    "df['Game_ID'] = df['Game_ID'].str.replace(',', '')\n",
    "\n",
    "# Remove any hyphens from the team names if any\n",
    "df['Home_Team'] = df['Home_Team'].str.replace('-', ' ')\n",
    "df['Away_Team'] = df['Away_Team'].str.replace('-', ' ')\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df['Game_ID'] = df.apply(lambda row: f'{row.Date}-{row.Home_Team}-{row.Away_Team}', axis=1)\n",
    "\n",
    "## Filter out games that have not been played yet\n",
    "df = df[df['Home_Score'] != '']\n",
    "\n",
    "# Replace Nan values in metrics column with empty string\n",
    "df['Metrics_Link'] = df['Metrics_Link'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f58d154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### INSPECT RESULTING DATAFRAME\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename to df_2024\n",
    "# df_2024 = df.copy()\n",
    "df_2023 = df.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1706f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the resulting DataFrames 2023 and 2024 and combine\n",
    "# df_2023.head(), df_2024.head()\n",
    "\n",
    "df_new = pd.concat([df_2023, df_2024], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c5918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all time table thru 2023\n",
    "df_thru_2023 = pd.read_csv(\"../data/tables/results_all_time_thru_2023.csv\")\n",
    "\n",
    "# check the dataframe\n",
    "df_thru_2023.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51e02fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the new dataframe into the all time dataframe\n",
    "df_all_time = pd.concat([df_thru_2023, df_new], axis=0)\n",
    "\n",
    "# Check and normalize the column data types\n",
    "df_all_time = df_all_time.convert_dtypes()\n",
    "\n",
    "# save to CSV\n",
    "df_all_time.to_csv(\"../data/tables/results_all_time.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202c29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_time.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e083bf7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09d8892f",
   "metadata": {},
   "source": [
    "# Below FIRST DRAFT - POC - All Time Games above below 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847c75d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1) Load & normalize ---\n",
    "\n",
    "all_time_path = os.path.join(\"..\", \"data\", \"tables\", \"results_all_time_thru_2023.csv\")\n",
    "DATA_PATH = all_time_path\n",
    "\n",
    "df = pd.read_csv(all_time_path)\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df['Home_Score'] = pd.to_numeric(df['Home_Score'], errors='coerce').astype('Int64')\n",
    "df['Away_Score'] = pd.to_numeric(df['Away_Score'], errors='coerce').astype('Int64')\n",
    "df['OT'] = df['OT'].astype(str).str.lower().replace({'nan':''})\n",
    "df['Game_Notes'] = df['Game_Notes'].astype(str).str.lower()\n",
    "\n",
    "def extract_id(s):\n",
    "    m = re.search(r\"/reports/team/.+?/(\\d+)\", str(s))\n",
    "    return int(m.group(1)) if m else pd.NA\n",
    "\n",
    "df['Home_Team_ID'] = df['Home_Team_Link'].apply(extract_id)\n",
    "df['Away_Team_ID'] = df['Away_Team_Link'].apply(extract_id)\n",
    "\n",
    "# --- 2) Filter what counts ---\n",
    "mask_both_teams = df['Home_Team_ID'].notna() & df['Away_Team_ID'].notna()\n",
    "mask_exhib = df['Game_Notes'].str.contains('exhib', na=False)\n",
    "mask_cancel = df['Game_Notes'].str.contains('cancel', na=False)\n",
    "df = df[mask_both_teams & ~mask_exhib & ~mask_cancel].copy()\n",
    "\n",
    "# --- 3) Explode to long ---\n",
    "home = df.rename(columns={\n",
    "    'Home_Team':'team','Home_Team_ID':'team_id','Home_Score':'team_score',\n",
    "    'Away_Team':'opp','Away_Team_ID':'opp_id','Away_Score':'opp_score'\n",
    "}).assign(venue='H')\n",
    "away = df.rename(columns={\n",
    "    'Away_Team':'team','Away_Team_ID':'team_id','Away_Score':'team_score',\n",
    "    'Home_Team':'opp','Home_Team_ID':'opp_id','Home_Score':'opp_score'\n",
    "}).assign(venue='A')\n",
    "\n",
    "long = pd.concat([home, away], ignore_index=True)\n",
    "\n",
    "keep_cols = ['Date','Season_Year','Game_ID','team','team_id','opp','opp_id',\n",
    "             'team_score','opp_score','venue','OT','Conference','Game_Notes']\n",
    "long = long[keep_cols].copy()\n",
    "\n",
    "# --- 4) Outcome & increment ---\n",
    "long['result'] = np.select(\n",
    "    [long['team_score'] > long['opp_score'],\n",
    "     long['team_score'] < long['opp_score']],\n",
    "    ['W','L'],\n",
    "    default='T'\n",
    ")\n",
    "long['is_win']  = (long['result']=='W').astype(int)\n",
    "long['is_loss'] = (long['result']=='L').astype(int)\n",
    "long['is_tie']  = (long['result']=='T').astype(int)\n",
    "\n",
    "# For the .500 curve: ties are neutral\n",
    "long['delta'] = long['is_win'] - long['is_loss']  # +1 / -1 / 0\n",
    "\n",
    "# --- 5) Sort & sequence ---\n",
    "long = long.sort_values(['team_id','Date','Game_ID'], kind='mergesort')\n",
    "long['gp'] = long.groupby('team_id').cumcount() + 1\n",
    "\n",
    "# --- 6) Cumulative record & games above .500 ---\n",
    "long['cum_w'] = long.groupby('team_id')['is_win'].cumsum()\n",
    "long['cum_l'] = long.groupby('team_id')['is_loss'].cumsum()\n",
    "long['cum_t'] = long.groupby('team_id')['is_tie'].cumsum()\n",
    "long['games_above_500'] = long['cum_w'] - long['cum_l']\n",
    "long['record_str'] = long['cum_w'].astype(str)+'-'+long['cum_l'].astype(str)+'-'+long['cum_t'].astype(str)\n",
    "\n",
    "timeline = long[['team_id','team','Date','Game_ID','Season_Year','gp',\n",
    "                 'result','delta','cum_w','cum_l','cum_t','games_above_500']].copy()\n",
    "\n",
    "# --- 7) Milestones for annotations ---\n",
    "def team_summary(g):\n",
    "    g = g.sort_values('Date')\n",
    "    max_idx = g['games_above_500'].idxmax()\n",
    "    min_idx = g['games_above_500'].idxmin()\n",
    "    out = {\n",
    "        'team': g['team'].iloc[0],\n",
    "        'first_date': g['Date'].min(),\n",
    "        'last_date': g['Date'].max(),\n",
    "        'max_point': g.loc[max_idx, 'games_above_500'],\n",
    "        'max_date': g.loc[max_idx, 'Date'],\n",
    "        'min_point': g.loc[min_idx, 'games_above_500'],\n",
    "        'min_date': g.loc[min_idx, 'Date'],\n",
    "        'final_w': g['cum_w'].iloc[-1],\n",
    "        'final_l': g['cum_l'].iloc[-1],\n",
    "        'final_t': g['cum_t'].iloc[-1],\n",
    "    }\n",
    "    # last time exactly at .500 (if ever)\n",
    "    at500 = g[g['games_above_500']==0]\n",
    "    out['last_500_date'] = at500['Date'].iloc[-1] if not at500.empty else pd.NaT\n",
    "    return pd.Series(out)\n",
    "\n",
    "summary = timeline.groupby('team_id').apply(team_summary).reset_index()\n",
    "\n",
    "# --- 8) Save for plotting ---\n",
    "timeline.to_parquet('team_timeseries.parquet', index=False)\n",
    "summary.to_parquet('team_summary.parquet', index=False)\n",
    "# (or .csv if you prefer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6033d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run full pipeline (concise version) and save outputs, avoiding any UI display calls.\n",
    "\n",
    "import re, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# DATA_PATH = Path(\"/mnt/data/results_table_all_time_thru 2023.csv\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "def find_col(possible, cols):\n",
    "    norm = {c.lower().replace(\" \", \"_\"): c for c in cols}\n",
    "    for p in possible:\n",
    "        key = p.lower().replace(\" \", \"_\")\n",
    "        if key in norm: return norm[key]\n",
    "    return None\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "c_date   = find_col([\"Date\"], cols)\n",
    "c_season = find_col([\"Season_Year\",\"Season\",\"Season Year\"], cols)\n",
    "c_gmid   = find_col([\"Game_ID\",\"GameID\",\"Game Id\",\"gid\"], cols)\n",
    "c_htm    = find_col([\"Home_Team\",\"Home Team\",\"Home\"], cols)\n",
    "c_atm    = find_col([\"Away_Team\",\"Away Team\",\"Away\",\"Visitor_Team\",\"Visitor Team\"], cols)\n",
    "c_hsc    = find_col([\"Home_Score\",\"Home Score\",\"HomeGoals\",\"Home_Goals\"], cols)\n",
    "c_asc    = find_col([\"Away_Score\",\"Away Score\",\"AwayGoals\",\"Away_Goals\"], cols)\n",
    "c_ot     = find_col([\"OT\",\"OT_SO\",\"OT/SO\",\"Overtime\",\"Shootout\"], cols)\n",
    "c_notes  = find_col([\"Game_Notes\",\"Notes\",\"Game Notes\"], cols)\n",
    "c_hlnk   = find_col([\"Home_Team_Link\",\"Home Team Link\",\"Home_Link\"], cols)\n",
    "c_alnk   = find_col([\"Away_Team_Link\",\"Away Team Link\",\"Away_Link\"], cols)\n",
    "\n",
    "df[c_date] = pd.to_datetime(df[c_date], errors=\"coerce\")\n",
    "if c_season is None:\n",
    "    c_season=\"__Season_Fallback__\"; df[c_season]=df[c_date].dt.year\n",
    "if c_gmid is None:\n",
    "    c_gmid=\"__GameID_Fallback__\"; df[c_gmid]=np.arange(1,len(df)+1)\n",
    "if c_hsc: df[c_hsc]=pd.to_numeric(df[c_hsc], errors=\"coerce\").astype(\"Int64\")\n",
    "if c_asc: df[c_asc]=pd.to_numeric(df[c_asc], errors=\"coerce\").astype(\"Int64\")\n",
    "if c_ot: df[c_ot]=df[c_ot].astype(str).str.lower()\n",
    "if c_notes: df[c_notes]=df[c_notes].astype(str).str.lower()\n",
    "\n",
    "def extract_team_id(u):\n",
    "    if pd.isna(u): return pd.NA\n",
    "    m=re.search(r\"/reports/team/.+?/(\\d+)\", str(u))\n",
    "    return int(m.group(1)) if m else pd.NA\n",
    "\n",
    "if c_hlnk and c_alnk:\n",
    "    df[\"Home_Team_ID\"]=df[c_hlnk].apply(extract_team_id)\n",
    "    df[\"Away_Team_ID\"]=df[c_alnk].apply(extract_team_id)\n",
    "else:\n",
    "    df[\"Home_Team_ID\"]=df[c_htm].astype(str).str.strip().str.lower().map(lambda s: abs(hash(s))%(10**9))\n",
    "    df[\"Away_Team_ID\"]=df[c_atm].astype(str).str.strip().str.lower().map(lambda s: abs(hash(s))%(10**9))\n",
    "\n",
    "mask_valid = df[\"Home_Team_ID\"].notna() & df[\"Away_Team_ID\"].notna()\n",
    "mask_exhib = df[c_notes].str.contains(\"exhib\", na=False) if c_notes else False\n",
    "mask_cancel= df[c_notes].str.contains(\"cancel\",na=False) if c_notes else False\n",
    "df = df[mask_valid & ~mask_exhib & ~mask_cancel].copy()\n",
    "\n",
    "home = df.rename(columns={\n",
    "    c_date:\"Date\", c_season:\"Season_Year\", c_gmid:\"Game_ID\",\n",
    "    c_htm:\"team\",\"Home_Team_ID\":\"team_id\", c_hsc:\"team_score\",\n",
    "    c_atm:\"opp\",\"Away_Team_ID\":\"opp_id\", c_asc:\"opp_score\",\n",
    "    **({c_ot:\"OT\"} if c_ot else {}), **({c_notes:\"Game_Notes\"} if c_notes else {})\n",
    "})[[\"Date\",\"Season_Year\",\"Game_ID\",\"team\",\"team_id\",\"team_score\",\"opp\",\"opp_id\",\"opp_score\"] + ([\"OT\"] if c_ot else []) + ([\"Game_Notes\"] if c_notes else [])]\n",
    "home[\"venue\"]=\"H\"\n",
    "\n",
    "away = df.rename(columns={\n",
    "    c_date:\"Date\", c_season:\"Season_Year\", c_gmid:\"Game_ID\",\n",
    "    c_atm:\"team\",\"Away_Team_ID\":\"team_id\", c_asc:\"team_score\",\n",
    "    c_htm:\"opp\",\"Home_Team_ID\":\"opp_id\", c_hsc:\"opp_score\",\n",
    "    **({c_ot:\"OT\"} if c_ot else {}), **({c_notes:\"Game_Notes\"} if c_notes else {})\n",
    "})[[\"Date\",\"Season_Year\",\"Game_ID\",\"team\",\"team_id\",\"team_score\",\"opp\",\"opp_id\",\"opp_score\"] + ([\"OT\"] if c_ot else []) + ([\"Game_Notes\"] if c_notes else [])]\n",
    "away[\"venue\"]=\"A\"\n",
    "\n",
    "long=pd.concat([home,away], ignore_index=True)\n",
    "long=long[long[\"team_score\"].notna() & long[\"opp_score\"].notna()].copy()\n",
    "\n",
    "long[\"result\"]=np.where(long[\"team_score\"]>long[\"opp_score\"],\"W\",np.where(long[\"team_score\"]<long[\"opp_score\"],\"L\",\"T\"))\n",
    "long[\"is_win\"]=(long[\"result\"]==\"W\").astype(int)\n",
    "long[\"is_loss\"]=(long[\"result\"]==\"L\").astype(int)\n",
    "long[\"is_tie\"]=(long[\"result\"]==\"T\").astype(int)\n",
    "long=long.sort_values([\"team_id\",\"Date\",\"Game_ID\"], kind=\"mergesort\")\n",
    "long[\"gp\"]=long.groupby(\"team_id\").cumcount()+1\n",
    "long[\"cum_w\"]=long.groupby(\"team_id\")[\"is_win\"].cumsum()\n",
    "long[\"cum_l\"]=long.groupby(\"team_id\")[\"is_loss\"].cumsum()\n",
    "long[\"cum_t\"]=long.groupby(\"team_id\")[\"is_tie\"].cumsum()\n",
    "long[\"games_above_500\"]=long[\"cum_w\"]-long[\"cum_l\"]\n",
    "long[\"delta\"]=long[\"is_win\"]-long[\"is_loss\"]\n",
    "\n",
    "timeline=long[[\"team_id\",\"team\",\"Date\",\"Game_ID\",\"Season_Year\",\"gp\",\"result\",\"delta\",\"cum_w\",\"cum_l\",\"cum_t\",\"games_above_500\",\"venue\"]].copy()\n",
    "\n",
    "def summarize(g):\n",
    "    g=g.sort_values(\"Date\")\n",
    "    at500=g[g[\"games_above_500\"]==0]\n",
    "    return pd.Series({\n",
    "        \"team\":g[\"team\"].iloc[0],\n",
    "        \"first_date\":g[\"Date\"].min(),\n",
    "        \"last_date\":g[\"Date\"].max(),\n",
    "        \"max_point\":g[\"games_above_500\"].max(),\n",
    "        \"max_date\":g.loc[g[\"games_above_500\"].idxmax(),\"Date\"],\n",
    "        \"min_point\":g[\"games_above_500\"].min(),\n",
    "        \"min_date\":g.loc[g[\"games_above_500\"].idxmin(),\"Date\"],\n",
    "        \"final_w\":g[\"cum_w\"].iloc[-1],\n",
    "        \"final_l\":g[\"cum_l\"].iloc[-1],\n",
    "        \"final_t\":g[\"cum_t\"].iloc[-1],\n",
    "        \"final_games_above_500\":g[\"games_above_500\"].iloc[-1],\n",
    "        \"last_500_date\": at500[\"Date\"].iloc[-1] if not at500.empty else pd.NaT,\n",
    "    })\n",
    "\n",
    "summary = timeline.groupby(\"team_id\", group_keys=False).apply(summarize).reset_index()\n",
    "\n",
    "out_dir=Path(\"../TEMP\")\n",
    "timeline.to_parquet(out_dir/\"team_timeseries.parquet\", index=False)\n",
    "summary.to_parquet(out_dir/\"team_summary.parquet\", index=False)\n",
    "timeline.to_csv(out_dir/\"team_timeseries.csv\", index=False)\n",
    "summary.to_csv(out_dir/\"team_summary.csv\", index=False)\n",
    "\n",
    "print(\"Done. Files created in /mnt/data:\")\n",
    "print(\"- team_timeseries.parquet  |  team_timeseries.csv\")\n",
    "print(\"- team_summary.parquet     |  team_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a18b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "transform_games_to_team_timeseries.py\n",
    "\n",
    "Purpose\n",
    "-------\n",
    "Turn a \"one row per game\" college hockey CSV into:\n",
    "  1) a per-team, per-game time series with cumulative record and games-above-.500\n",
    "  2) a per-team summary for annotations (max/min points, last .500 date, final record)\n",
    "\n",
    "Key Decisions\n",
    "-------------\n",
    "- .500 curve uses the classic definition: +1 for a WIN, -1 for a LOSS, 0 for a TIE.\n",
    "- Ties do not move the line (they still appear in the cumulative record).\n",
    "- Exhibitions / cancellations are excluded if noted in the data.\n",
    "- If official team link IDs are missing, a stable hash of team names is used for `team_id`.\n",
    "\n",
    "Output\n",
    "------\n",
    "- team_timeseries.csv  : one row per team per game with 'games_above_500'\n",
    "- team_summary.csv     : per-team milestones for chart annotations\n",
    "\n",
    "Author: you + ChatGPT\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Optional, List\n",
    "\n",
    "# ---------- Utilities ---------------------------------------------------------\n",
    "\n",
    "def find_col(possible: List[str], cols: List[str]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Fuzzy column resolver: try common alternatives, tolerant to spaces/underscores/case.\n",
    "    Returns the first match found or None.\n",
    "    \"\"\"\n",
    "    norm = {c.lower().replace(\" \", \"_\"): c for c in cols}\n",
    "    for p in possible:\n",
    "        key = p.lower().replace(\" \", \"_\")\n",
    "        if key in norm:\n",
    "            return norm[key]\n",
    "    return None\n",
    "\n",
    "def extract_team_id(url_like) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    If your source has official team links, extract the numeric ID from a pattern like:\n",
    "      '/reports/team/<something>/<id>'\n",
    "    Returns NA if no match.\n",
    "    \"\"\"\n",
    "    if pd.isna(url_like):\n",
    "        return pd.NA\n",
    "    m = re.search(r\"/reports/team/.+?/(\\d+)\", str(url_like))\n",
    "    return int(m.group(1)) if m else pd.NA\n",
    "\n",
    "\n",
    "# ---------- Main transformation ----------------------------------------------\n",
    "\n",
    "def build_timeseries(input_csv: str, out_dir: str = \"./\") -> None:\n",
    "    out_path = Path(out_dir)\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Load & normalize ------------------------------------------------------\n",
    "    df_raw = pd.read_csv(input_csv)\n",
    "    cols = df_raw.columns.tolist()\n",
    "\n",
    "    c_date   = find_col([\"Date\"], cols)\n",
    "    c_season = find_col([\"Season_Year\",\"Season\",\"Season Year\"], cols)\n",
    "    c_gmid   = find_col([\"Game_ID\",\"GameID\",\"Game Id\",\"gid\"], cols)\n",
    "\n",
    "    c_htm    = find_col([\"Home_Team\",\"Home Team\",\"Home\"], cols)\n",
    "    c_atm    = find_col([\"Away_Team\",\"Away Team\",\"Away\",\"Visitor_Team\",\"Visitor Team\"], cols)\n",
    "    c_hsc    = find_col([\"Home_Score\",\"Home Score\",\"HomeGoals\",\"Home_Goals\"], cols)\n",
    "    c_asc    = find_col([\"Away_Score\",\"Away Score\",\"AwayGoals\",\"Away_Goals\"], cols)\n",
    "\n",
    "    c_ot     = find_col([\"OT\",\"OT_SO\",\"OT/SO\",\"Overtime\",\"Shootout\"], cols)\n",
    "    c_notes  = find_col([\"Game_Notes\",\"Notes\",\"Game Notes\"], cols)\n",
    "\n",
    "    c_hlnk   = find_col([\"Home_Team_Link\",\"Home Team Link\",\"Home_Link\"], cols)\n",
    "    c_alnk   = find_col([\"Away_Team_Link\",\"Away Team Link\",\"Away_Link\"], cols)\n",
    "\n",
    "    if c_date is None:\n",
    "        raise ValueError(\"No 'Date' column found—cannot build timelines.\")\n",
    "\n",
    "    df = df_raw.copy()\n",
    "    df[c_date] = pd.to_datetime(df[c_date], errors=\"coerce\")\n",
    "\n",
    "    if c_season is None:\n",
    "        # Simple fallback: use calendar year of the date.\n",
    "        c_season = \"__Season_Fallback__\"\n",
    "        df[c_season] = df[c_date].dt.year\n",
    "\n",
    "    if c_gmid is None:\n",
    "        # Stable fallback game_id if not supplied\n",
    "        c_gmid = \"__GameID_Fallback__\"\n",
    "        df[c_gmid] = np.arange(1, len(df) + 1)\n",
    "\n",
    "    # Scores\n",
    "    for score_col in [c_hsc, c_asc]:\n",
    "        if score_col is not None:\n",
    "            df[score_col] = pd.to_numeric(df[score_col], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # Text normalization\n",
    "    if c_ot is not None:\n",
    "        df[c_ot] = df[c_ot].astype(str).str.lower()\n",
    "    if c_notes is not None:\n",
    "        df[c_notes] = df[c_notes].astype(str).str.lower()\n",
    "\n",
    "    # 2) Team IDs --------------------------------------------------------------\n",
    "    # Prefer official IDs from link columns; otherwise, make a stable hash of team names.\n",
    "    if c_hlnk and c_alnk:\n",
    "        df[\"Home_Team_ID\"] = df[c_hlnk].apply(extract_team_id)\n",
    "        df[\"Away_Team_ID\"] = df[c_alnk].apply(extract_team_id)\n",
    "    else:\n",
    "        df[\"Home_Team_ID\"] = df[c_htm].astype(str).str.strip().str.lower().map(lambda s: abs(hash(s)) % (10**9))\n",
    "        df[\"Away_Team_ID\"] = df[c_atm].astype(str).str.strip().str.lower().map(lambda s: abs(hash(s)) % (10**9))\n",
    "\n",
    "    # 3) Filter what shouldn’t count ------------------------------------------\n",
    "    mask_valid = df[\"Home_Team_ID\"].notna() & df[\"Away_Team_ID\"].notna()\n",
    "    if c_notes is not None:\n",
    "        mask_exhib  = df[c_notes].str.contains(\"exhib\",  na=False)\n",
    "        mask_cancel = df[c_notes].str.contains(\"cancel\", na=False)\n",
    "    else:\n",
    "        mask_exhib = mask_cancel = False\n",
    "\n",
    "    df = df[mask_valid & ~mask_exhib & ~mask_cancel].copy()\n",
    "\n",
    "    # 4) Explode to long (one row per team per game) --------------------------\n",
    "    home = df.rename(columns={\n",
    "        c_date:\"Date\", c_season:\"Season_Year\", c_gmid:\"Game_ID\",\n",
    "        c_htm:\"team\", \"Home_Team_ID\":\"team_id\", c_hsc:\"team_score\",\n",
    "        c_atm:\"opp\", \"Away_Team_ID\":\"opp_id\", c_asc:\"opp_score\",\n",
    "        **({c_ot:\"OT\"} if c_ot else {}), **({c_notes:\"Game_Notes\"} if c_notes else {}),\n",
    "    })\n",
    "    home = home[[\"Date\",\"Season_Year\",\"Game_ID\",\"team\",\"team_id\",\"team_score\",\"opp\",\"opp_id\",\"opp_score\"] +\n",
    "                ([\"OT\"] if c_ot else []) + ([\"Game_Notes\"] if c_notes else [])]\n",
    "    home[\"venue\"] = \"H\"\n",
    "\n",
    "    away = df.rename(columns={\n",
    "        c_date:\"Date\", c_season:\"Season_Year\", c_gmid:\"Game_ID\",\n",
    "        c_atm:\"team\", \"Away_Team_ID\":\"team_id\", c_asc:\"team_score\",\n",
    "        c_htm:\"opp\", \"Home_Team_ID\":\"opp_id\", c_hsc:\"opp_score\",\n",
    "        **({c_ot:\"OT\"} if c_ot else {}), **({c_notes:\"Game_Notes\"} if c_notes else {}),\n",
    "    })\n",
    "    away = away[[\"Date\",\"Season_Year\",\"Game_ID\",\"team\",\"team_id\",\"team_score\",\"opp\",\"opp_id\",\"opp_score\"] +\n",
    "                ([\"OT\"] if c_ot else []) + ([\"Game_Notes\"] if c_notes else [])]\n",
    "    away[\"venue\"] = \"A\"\n",
    "\n",
    "    long = pd.concat([home, away], ignore_index=True)\n",
    "\n",
    "    # Drop rows without scores (postponed/unplayed/etc.)\n",
    "    long = long[long[\"team_score\"].notna() & long[\"opp_score\"].notna()].copy()\n",
    "\n",
    "    # 5) Outcome & increment for the .500 curve --------------------------------\n",
    "    long[\"result\"]  = np.where(long[\"team_score\"] > long[\"opp_score\"], \"W\",\n",
    "                        np.where(long[\"team_score\"] < long[\"opp_score\"], \"L\", \"T\"))\n",
    "    long[\"is_win\"]  = (long[\"result\"] == \"W\").astype(int)\n",
    "    long[\"is_loss\"] = (long[\"result\"] == \"L\").astype(int)\n",
    "    long[\"is_tie\"]  = (long[\"result\"] == \"T\").astype(int)\n",
    "\n",
    "    # .500 line increment (ties = 0)\n",
    "    long[\"delta\"]   = long[\"is_win\"] - long[\"is_loss\"]\n",
    "\n",
    "    # 6) Order & per-team sequencing ------------------------------------------\n",
    "    long = long.sort_values([\"team_id\",\"Date\",\"Game_ID\"], kind=\"mergesort\")\n",
    "    long[\"gp\"] = long.groupby(\"team_id\").cumcount() + 1\n",
    "\n",
    "    # 7) Cumulative record & games-above-.500 ----------------------------------\n",
    "    long[\"cum_w\"] = long.groupby(\"team_id\")[\"is_win\"].cumsum()\n",
    "    long[\"cum_l\"] = long.groupby(\"team_id\")[\"is_loss\"].cumsum()\n",
    "    long[\"cum_t\"] = long.groupby(\"team_id\")[\"is_tie\"].cumsum()\n",
    "\n",
    "    # This is the Y-value for the chart\n",
    "    long[\"games_above_500\"] = long[\"cum_w\"] - long[\"cum_l\"]\n",
    "\n",
    "    # --- Goal Differential (GD) -----------------------------------------------\n",
    "    # Per-game goal differential from the *team's* perspective.\n",
    "    # For shootouts: most NCAA datasets store regulation+OT goals only (SO adds no goals),\n",
    "    # so this calculation should already be correct. If your table encodes SO winner goals,\n",
    "    # strip those first.\n",
    "    long[\"gd\"] = (long[\"team_score\"].astype(int) - long[\"opp_score\"].astype(int))\n",
    "\n",
    "    # Cumulative all-time GD: this is the Y-value for a GD curve (step-like, changes only on game days)\n",
    "    long[\"cum_gd\"] = long.groupby(\"team_id\")[\"gd\"].cumsum()\n",
    "\n",
    "\n",
    "    timeline = long[[\n",
    "        \"team_id\",\"team\",\"Date\",\"Game_ID\",\"Season_Year\",\"gp\",\n",
    "        \"team_score\",\"opp_score\",          # (optional but handy)\n",
    "        \"result\",\"delta\",                  # win/loss increment (for .500 curve)\n",
    "        \"gd\",\"cum_gd\",                     # <-- NEW: per-game and cumulative GD\n",
    "        \"cum_w\",\"cum_l\",\"cum_t\",\"games_above_500\",\n",
    "        \"venue\"\n",
    "    ]].copy()\n",
    "\n",
    "    # timeline = long[[\n",
    "    #     \"team_id\",\"team\",\"Date\",\"Game_ID\",\"Season_Year\",\"gp\",\n",
    "    #     \"result\",\"delta\",\"cum_w\",\"cum_l\",\"cum_t\",\"games_above_500\",\"venue\"\n",
    "    # ]].copy()\n",
    "\n",
    "    # 8) Per-team milestones (for annotations) --------------------------------\n",
    "    def summarize_team(g: pd.DataFrame) -> pd.Series:\n",
    "        g = g.sort_values(\"Date\")\n",
    "        at500 = g[g[\"games_above_500\"] == 0]\n",
    "\n",
    "        # Locate max/min cumulative GD rows\n",
    "        max_gd_idx = g[\"cum_gd\"].idxmax()\n",
    "        min_gd_idx = g[\"cum_gd\"].idxmin()\n",
    "\n",
    "        return pd.Series({\n",
    "            \"team\": g[\"team\"].iloc[0],\n",
    "            \"first_date\": g[\"Date\"].min(),\n",
    "            \"last_date\":  g[\"Date\"].max(),\n",
    "\n",
    "            # .500 curve milestones (you already had these)\n",
    "            \"max_point\":  g[\"games_above_500\"].max(),\n",
    "            \"max_date\":   g.loc[g[\"games_above_500\"].idxmax(),\"Date\"],\n",
    "            \"min_point\":  g[\"games_above_500\"].min(),\n",
    "            \"min_date\":   g.loc[g[\"games_above_500\"].idxmin(),\"Date\"],\n",
    "            \"final_w\":    g[\"cum_w\"].iloc[-1],\n",
    "            \"final_l\":    g[\"cum_l\"].iloc[-1],\n",
    "            \"final_t\":    g[\"cum_t\"].iloc[-1],\n",
    "            \"final_games_above_500\": g[\"games_above_500\"].iloc[-1],\n",
    "            \"last_500_date\": at500[\"Date\"].iloc[-1] if not at500.empty else pd.NaT,\n",
    "\n",
    "            # --- NEW: GD milestones\n",
    "            \"max_cum_gd\": g.loc[max_gd_idx, \"cum_gd\"],\n",
    "            \"max_cum_gd_date\": g.loc[max_gd_idx, \"Date\"],\n",
    "            \"min_cum_gd\": g.loc[min_gd_idx, \"cum_gd\"],\n",
    "            \"min_cum_gd_date\": g.loc[min_gd_idx, \"Date\"],\n",
    "            \"final_cum_gd\": g[\"cum_gd\"].iloc[-1],\n",
    "        })\n",
    "\n",
    "    # def summarize_team(g: pd.DataFrame) -> pd.Series:\n",
    "    #     g = g.sort_values(\"Date\")\n",
    "    #     at500 = g[g[\"games_above_500\"] == 0]\n",
    "    #     return pd.Series({\n",
    "    #         \"team\": g[\"team\"].iloc[0],\n",
    "    #         \"first_date\": g[\"Date\"].min(),\n",
    "    #         \"last_date\":  g[\"Date\"].max(),\n",
    "    #         \"max_point\":  g[\"games_above_500\"].max(),\n",
    "    #         \"max_date\":   g.loc[g[\"games_above_500\"].idxmax(),\"Date\"],\n",
    "    #         \"min_point\":  g[\"games_above_500\"].min(),\n",
    "    #         \"min_date\":   g.loc[g[\"games_above_500\"].idxmin(),\"Date\"],\n",
    "    #         \"final_w\":    g[\"cum_w\"].iloc[-1],\n",
    "    #         \"final_l\":    g[\"cum_l\"].iloc[-1],\n",
    "    #         \"final_t\":    g[\"cum_t\"].iloc[-1],\n",
    "    #         \"final_games_above_500\": g[\"games_above_500\"].iloc[-1],\n",
    "    #         \"last_500_date\": at500[\"Date\"].iloc[-1] if not at500.empty else pd.NaT,\n",
    "    #     })\n",
    "\n",
    "    summary = timeline.groupby(\"team_id\", group_keys=False).apply(summarize_team).reset_index()\n",
    "\n",
    "    # 9) Save outputs (CSV by default; Parquet lines are included if you have pyarrow) ----\n",
    "    timeline.to_csv(out_path / \"../TEMP/team_timeseries.csv\", index=False)\n",
    "    summary.to_csv(out_path / \"../TEMP/team_summary.csv\", index=False)\n",
    "\n",
    "    # If you prefer Parquet (faster; needs pyarrow or fastparquet):\n",
    "    # timeline.to_parquet(out_path / \"team_timeseries.parquet\", index=False)\n",
    "    # summary.to_parquet(out_path / \"team_summary.parquet\", index=False)\n",
    "\n",
    "\n",
    "# ---------- Optional: simple plotting helper ---------------------------------\n",
    "# (Keeps colors/style up to you; this just draws a step-like line.)\n",
    "def plot_team_curve(timeline: pd.DataFrame, team_name_or_id):\n",
    "    \"\"\"\n",
    "    Example usage:\n",
    "        tl = pd.read_csv(\"team_timeseries.csv\", parse_dates=[\"Date\"])\n",
    "        plot_team_curve(tl, team_name_or_id=123456789)  # or a team name string\n",
    "\n",
    "    This produces a basic line of `games_above_500` vs. date.\n",
    "    Add your own shading/annotations to mimic the NHL-style chart.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    if isinstance(team_name_or_id, (int, np.integer)):\n",
    "        g = timeline[timeline[\"team_id\"] == team_name_or_id].copy()\n",
    "        label = str(team_name_or_id)\n",
    "    else:\n",
    "        g = timeline[timeline[\"team\"].str.casefold() == str(team_name_or_id).casefold()].copy()\n",
    "        label = str(team_name_or_id)\n",
    "\n",
    "    g = g.sort_values(\"Date\")\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.plot(g[\"Date\"], g[\"games_above_500\"], linewidth=1.25, label=label)\n",
    "    plt.axhline(0, linewidth=1)\n",
    "    plt.xlabel(\"Date\"); plt.ylabel(\"Games Above/Below .500\")\n",
    "    plt.title(f\"{g['team'].iloc[0] if not g.empty else label}: Historical Performance\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# # ---------- Run from a notebook/script ---------------------------------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     build_timeseries(DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797a4f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot of a team\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Reload & filter (idempotent)\n",
    "tl = pd.read_csv(Path(\"../TEMP/team_summary.csv\"), parse_dates=[\"Date\"])\n",
    "team_name = \"Providence\"\n",
    "g = tl[tl[\"team\"].str.casefold() == team_name.casefold()].copy().sort_values(\"Date\")\n",
    "\n",
    "# Convert to numpy-friendly arrays\n",
    "x_vals = g[\"Date\"].values\n",
    "y_vals = g[\"games_above_500\"].astype(float).values  # ensure numeric dtype\n",
    "\n",
    "# Milestones\n",
    "max_idx = int(np.nanargmax(y_vals))\n",
    "min_idx = int(np.nanargmin(y_vals))\n",
    "last_500 = g[g[\"games_above_500\"] == 0][\"Date\"].max()\n",
    "\n",
    "final_w = int(g[\"cum_w\"].iloc[-1])\n",
    "final_l = int(g[\"cum_l\"].iloc[-1])\n",
    "final_t = int(g[\"cum_t\"].iloc[-1])\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.step(x_vals, y_vals, where=\"post\", linewidth=1.5, label=team_name)\n",
    "\n",
    "# Shade above/below zero using default colors\n",
    "plt.fill_between(x_vals, 0.0, y_vals, where=y_vals>0, alpha=0.2, step=\"post\")\n",
    "plt.fill_between(x_vals, 0.0, y_vals, where=y_vals<0, alpha=0.2, step=\"post\")\n",
    "\n",
    "plt.axhline(0.0, linewidth=1)\n",
    "\n",
    "# Annotations\n",
    "plt.plot(x_vals[max_idx], y_vals[max_idx], marker=\"o\")\n",
    "plt.annotate(\n",
    "    f\"Highest: {int(y_vals[max_idx])}\\n{pd.to_datetime(x_vals[max_idx]).date()}\",\n",
    "    (x_vals[max_idx], y_vals[max_idx]), xytext=(10, 10), textcoords=\"offset points\"\n",
    ")\n",
    "plt.plot(x_vals[min_idx], y_vals[min_idx], marker=\"o\")\n",
    "plt.annotate(\n",
    "    f\"Lowest: {int(y_vals[min_idx])}\\n{pd.to_datetime(x_vals[min_idx]).date()}\",\n",
    "    (x_vals[min_idx], y_vals[min_idx]), xytext=(10, -20), textcoords=\"offset points\"\n",
    ")\n",
    "if pd.notna(last_500):\n",
    "    last_val = float(g.loc[g[\"Date\"] == last_500, \"games_above_500\"].iloc[-1])\n",
    "    plt.plot(last_500, last_val, marker=\"o\")\n",
    "    plt.annotate(f\"Last .500: {last_500.date()}\", (last_500, last_val),\n",
    "                 xytext=(10, 10), textcoords=\"offset points\")\n",
    "\n",
    "plt.title(f\"{team_name}: Games Above/Below .500 Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Games Above/Below .500\")\n",
    "\n",
    "final_str = f\"Final Record: {final_w}-{final_l}-{final_t}  (Δ {final_w - final_l})\"\n",
    "plt.gcf().text(0.99, 0.02, final_str, ha=\"right\", va=\"bottom\", bbox=dict(boxstyle=\"round,pad=0.3\"))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902e219f",
   "metadata": {},
   "source": [
    "## All Time Goal Differential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672fa6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Goal Differential (GD) -----------------------------------------------\n",
    "# # Per-game goal differential from the *team's* perspective.\n",
    "# # For shootouts: most NCAA datasets store regulation+OT goals only (SO adds no goals),\n",
    "# # so this calculation should already be correct. If your table encodes SO winner goals,\n",
    "# # strip those first.\n",
    "# long[\"gd\"] = (long[\"team_score\"].astype(int) - long[\"opp_score\"].astype(int))\n",
    "\n",
    "# # Cumulative all-time GD: this is the Y-value for a GD curve (step-like, changes only on game days)\n",
    "# long[\"cum_gd\"] = long.groupby(\"team_id\")[\"gd\"].cumsum()\n",
    "\n",
    "\n",
    "# timeline = long[[\n",
    "#     \"team_id\",\"team\",\"Date\",\"Game_ID\",\"Season_Year\",\"gp\",\n",
    "#     \"team_score\",\"opp_score\",          # (optional but handy)\n",
    "#     \"result\",\"delta\",                  # win/loss increment (for .500 curve)\n",
    "#     \"gd\",\"cum_gd\",                     # <-- NEW: per-game and cumulative GD\n",
    "#     \"cum_w\",\"cum_l\",\"cum_t\",\"games_above_500\",\n",
    "#     \"venue\"\n",
    "# ]].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a6b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def summarize_team(g: pd.DataFrame) -> pd.Series:\n",
    "#     g = g.sort_values(\"Date\")\n",
    "#     at500 = g[g[\"games_above_500\"] == 0]\n",
    "\n",
    "#     # Locate max/min cumulative GD rows\n",
    "#     max_gd_idx = g[\"cum_gd\"].idxmax()\n",
    "#     min_gd_idx = g[\"cum_gd\"].idxmin()\n",
    "\n",
    "#     return pd.Series({\n",
    "#         \"team\": g[\"team\"].iloc[0],\n",
    "#         \"first_date\": g[\"Date\"].min(),\n",
    "#         \"last_date\":  g[\"Date\"].max(),\n",
    "\n",
    "#         # .500 curve milestones (you already had these)\n",
    "#         \"max_point\":  g[\"games_above_500\"].max(),\n",
    "#         \"max_date\":   g.loc[g[\"games_above_500\"].idxmax(),\"Date\"],\n",
    "#         \"min_point\":  g[\"games_above_500\"].min(),\n",
    "#         \"min_date\":   g.loc[g[\"games_above_500\"].idxmin(),\"Date\"],\n",
    "#         \"final_w\":    g[\"cum_w\"].iloc[-1],\n",
    "#         \"final_l\":    g[\"cum_l\"].iloc[-1],\n",
    "#         \"final_t\":    g[\"cum_t\"].iloc[-1],\n",
    "#         \"final_games_above_500\": g[\"games_above_500\"].iloc[-1],\n",
    "#         \"last_500_date\": at500[\"Date\"].iloc[-1] if not at500.empty else pd.NaT,\n",
    "\n",
    "#         # --- NEW: GD milestones\n",
    "#         \"max_cum_gd\": g.loc[max_gd_idx, \"cum_gd\"],\n",
    "#         \"max_cum_gd_date\": g.loc[max_gd_idx, \"Date\"],\n",
    "#         \"min_cum_gd\": g.loc[min_gd_idx, \"cum_gd\"],\n",
    "#         \"min_cum_gd_date\": g.loc[min_gd_idx, \"Date\"],\n",
    "#         \"final_cum_gd\": g[\"cum_gd\"].iloc[-1],\n",
    "#     })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603cfaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_team_goal_diff_styled(timeline, team_name_or_id,\n",
    "                               era_marks=(1970, 1980, 1990, 2000, 2010, 2020, 2030),\n",
    "                               line_color=\"#E6A000\",       # warm golden line\n",
    "                               fill_above=\"#FFD98F\",       # light gold\n",
    "                               fill_below=\"#FFD98F\",       # same fill; tweak if you want 2-tone\n",
    "                               figsize=(16,6)):\n",
    "    \"\"\"\n",
    "    Draw a 'cumulative goal differential' chart styled like the .500 graphic.\n",
    "    Requires timeline to include: Date, cum_gd, cum_w, cum_l, cum_t.\n",
    "\n",
    "    Example:\n",
    "        tl = pd.read_csv(\"team_timeseries.csv\", parse_dates=[\"Date\"])\n",
    "        plot_team_goal_diff_styled(tl, \"Michigan State\")\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    if \"cum_gd\" not in timeline.columns:\n",
    "        raise ValueError(\"cum_gd missing from timeline. Re-run transform with GD patches.\")\n",
    "\n",
    "    # Select team\n",
    "    if isinstance(team_name_or_id, (int, np.integer)):\n",
    "        g = timeline[timeline[\"team_id\"] == team_name_or_id].copy()\n",
    "        label = str(team_name_or_id)\n",
    "    else:\n",
    "        g = timeline[timeline[\"team\"].str.casefold() == str(team_name_or_id).casefold()].copy()\n",
    "        label = str(team_name_or_id)\n",
    "\n",
    "    if g.empty:\n",
    "        raise ValueError(f\"No rows for team '{team_name_or_id}'\")\n",
    "\n",
    "    g = g.sort_values(\"Date\").reset_index(drop=True)\n",
    "    x = g[\"Date\"].values\n",
    "    y = g[\"cum_gd\"].astype(float).values\n",
    "\n",
    "    # Milestones\n",
    "    max_idx = int(np.nanargmax(y))\n",
    "    min_idx = int(np.nanargmin(y))\n",
    "    last_zero = g.loc[g[\"cum_gd\"] == 0, \"Date\"].max()  # most recent date at zero GD (if any)\n",
    "\n",
    "    # Final record & GD\n",
    "    final_w = int(g[\"cum_w\"].iloc[-1]); final_l = int(g[\"cum_l\"].iloc[-1]); final_t = int(g[\"cum_t\"].iloc[-1])\n",
    "    final_gd = int(g[\"cum_gd\"].iloc[-1])\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.step(x, y, where=\"post\", lw=2.2, color=line_color)\n",
    "    ax.fill_between(x, 0, y, where=y>0, step=\"post\", alpha=0.28, color=fill_above)\n",
    "    ax.fill_between(x, 0, y, where=y<0, step=\"post\", alpha=0.18, color=fill_below)\n",
    "    ax.axhline(0, lw=1.2, color=\"0.25\")\n",
    "\n",
    "    # Era/decade markers\n",
    "    for yr in era_marks:\n",
    "        ax.axvline(pd.Timestamp(f\"{yr}-01-01\"), ls=\"--\", lw=0.8, color=\"0.65\")\n",
    "\n",
    "    # Annotations: highest/lowest & last-zero-GD\n",
    "    ax.plot(g[\"Date\"].iloc[max_idx], y[max_idx], \"o\", ms=5, color=line_color)\n",
    "    ax.annotate(f\"Highest GD: {int(y[max_idx])}\\n{pd.to_datetime(x[max_idx]).date()}\",\n",
    "                (g[\"Date\"].iloc[max_idx], y[max_idx]), xytext=(10, 10),\n",
    "                textcoords=\"offset points\")\n",
    "\n",
    "    ax.plot(g[\"Date\"].iloc[min_idx], y[min_idx], \"o\", ms=5, color=line_color)\n",
    "    ax.annotate(f\"Lowest GD: {int(y[min_idx])}\\n{pd.to_datetime(x[min_idx]).date()}\",\n",
    "                (g[\"Date\"].iloc[min_idx], y[min_idx]), xytext=(10, -22),\n",
    "                textcoords=\"offset points\")\n",
    "\n",
    "    if pd.notna(last_zero):\n",
    "        last_val = float(g.loc[g[\"Date\"] == last_zero, \"cum_gd\"].iloc[-1])\n",
    "        ax.plot(last_zero, last_val, \"o\", ms=5, color=\"tab:purple\")\n",
    "        ax.annotate(f\"Last 0 GD: {last_zero.date()}\",\n",
    "                    (last_zero, last_val), xytext=(10, 10),\n",
    "                    textcoords=\"offset points\")\n",
    "\n",
    "    # Title & labels\n",
    "    title = g[\"team\"].iloc[0]\n",
    "    ax.set_title(f\"{title}: Cumulative Goal Differential Over Time\", pad=10)\n",
    "    ax.set_ylabel(\"Cumulative Goal Differential\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.margins(x=0.01)\n",
    "\n",
    "    # Footer badge\n",
    "    footer = f\"Final Record: {final_w}-{final_l}-{final_t}   Final GD: {final_gd:+d}\"\n",
    "    fig.text(0.99, 0.02, footer, ha=\"right\", va=\"bottom\",\n",
    "             bbox=dict(boxstyle=\"round,pad=0.35\", fc=\"#FFE7B8\", ec=line_color, lw=1.2))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcecbd60",
   "metadata": {},
   "source": [
    "### Call Goal Differential Plot\n",
    "- set tl = to team_summary table\n",
    "- pass tl and Team name string to plot_team_goal_diff_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2297a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = pd.read_csv(\"../data/tables/team_summary.csv\", parse_dates=[\"Date\"])\n",
    "\n",
    "if \"cum_gd\" not in tl.columns:\n",
    "    if {\"team_score\", \"opp_score\"}.issubset(tl.columns):\n",
    "        tl[\"gd\"] = tl[\"team_score\"].astype(\"int64\") - tl[\"opp_score\"].astype(\"int64\")\n",
    "        tl[\"cum_gd\"] = tl.groupby(\"team_id\")[\"gd\"].cumsum()\n",
    "        tl.to_csv(TIMELINE_CSV, index=False)\n",
    "        print(\"Patched timeline with gd/cum_gd and saved.\")\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Timeline missing cum_gd and also lacks team_score/opp_score. \"\n",
    "            \"Re-run the transform so those columns are included.\"\n",
    "        )\n",
    "else:\n",
    "    print(\"Timeline already has cum_gd.\")\n",
    "# ✅ Use the timeseries, not the summary\n",
    "# tl = pd.read_csv(\"../TEMP/team_timeseries.csv\", parse_dates=[\"Date\"])\n",
    "\n",
    "# sanity check\n",
    "# assert \"cum_gd\" in tl.columns and \"Date\" in tl.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfcf09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot\n",
    "plot_team_goal_diff_styled(tl, \"Michigan State\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
